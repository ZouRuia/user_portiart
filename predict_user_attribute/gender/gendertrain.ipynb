{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import LAC\n",
    "from sklearn.feature_selection import RFE\n",
    "import happybase\n",
    "from sklearn.cluster import KMeans \n",
    "import joblib\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" \n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_model(\n",
    "    input_number:int,\n",
    "    sentence_maxlen:int,\n",
    "    vocab_size:int,\n",
    "    tag_size:int,\n",
    "    embedding_dim:int,\n",
    "    embedding_matrix=None,\n",
    "    is_embedding_training:bool=True,\n",
    "    embedding_dropout_rate:float = 0.0,\n",
    "    learning_rate = 1e-3,\n",
    "    ):\n",
    "    \"\"\"建立模型\n",
    "    input:\n",
    "        sentence_maxlen : 句子的长度\n",
    "        vocab_size : 词的个数\n",
    "        tag_size : 分类的个数\n",
    "        embedding_dim : word2vec训练时设置的向量长度\n",
    "        embedding_matrix : word2vec词向量矩阵\n",
    "        is_embedding_training : embedding层是否加入训练\n",
    "        embedding_dropout_rate : embedding层dropout的比率\n",
    "    \"\"\"\n",
    "\n",
    "    input_list =[ \n",
    "        tf.keras.layers.Input(shape=(sentence_maxlen,),name=\"input{}\".format(i))\n",
    "        for i in range(input_number)\n",
    "    ]\n",
    "    #embedding层\n",
    "    if not (embedding_matrix is None):\n",
    "        embedding_layer = tf.keras.layers.Embedding(\n",
    "            input_dim = vocab_size,\n",
    "            output_dim = embedding_dim,\n",
    "            embeddings_initializer = tf.keras.initializers.Constant(embedding_matrix),\n",
    "            trainable = is_embedding_training,\n",
    "            input_length = sentence_maxlen,\n",
    "        )\n",
    "    else:\n",
    "        embedding_layer = tf.keras.layers.Embedding(\n",
    "            input_dim = vocab_size,\n",
    "            output_dim = embedding_dim,\n",
    "            trainable = is_embedding_training,\n",
    "            input_length = sentence_maxlen,\n",
    "        )\n",
    "    output_list = [\n",
    "        embedding_layer(input_list[i]) for i in range(input_number)\n",
    "    ]\n",
    "\n",
    "    embedding_dropout_layer = tf.keras.layers.Dropout(embedding_dropout_rate)\n",
    "    cnn_layer0 = tf.keras.layers.Conv1D(filters=128, kernel_size=10, strides=1, padding='valid',activation=\"tanh\")\n",
    "    cnn_layer1 = tf.keras.layers.MaxPool1D(2, padding='valid')\n",
    "    cnn_layer2 = tf.keras.layers.Flatten()\n",
    "    for layer in [embedding_dropout_layer,cnn_layer0,cnn_layer1,cnn_layer2]:\n",
    "        output_list = [\n",
    "            layer(output_list[i]) for i in range(input_number)\n",
    "        ]\n",
    "    output = tf.keras.layers.Concatenate()(output_list)\n",
    "    \n",
    "    # output = tf.keras.layers.Concatenate()(output_list)\n",
    "    # output = tf.keras.layers.Dropout(embedding_dropout_rate)(output)\n",
    "    # output = tf.keras.layers.Conv1D(filters=512, kernel_size=20, strides=1, padding='valid',activation=\"tanh\")(output)\n",
    "    # output = tf.keras.layers.MaxPool1D(2, padding='valid')(output)\n",
    "    # output = tf.keras.layers.Flatten()(output)\n",
    "\n",
    "    output = tf.keras.layers.Dropout(0.5)(output)\n",
    "    #output = tf.keras.layers.Dense(16, activation='tanh',kernel_regularizer=tf.keras.regularizers.l2())(output)\n",
    "\n",
    "    if tag_size > 2:\n",
    "        output = tf.keras.layers.Dense(tag_size, activation='softmax',use_bias=True,kernel_regularizer=tf.keras.regularizers.l2())(output)\n",
    "        # output = tf.keras.layers.Dense(tag_size, activation='softmax',use_bias=True)(output)\n",
    "        print(\"这是一个多分类模型\")\n",
    "    elif tag_size == 2:\n",
    "        output = tf.keras.layers.Dense(1, activation='sigmoid',use_bias=True,kernel_regularizer=tf.keras.regularizers.l2())(output)\n",
    "        # output = tf.keras.layers.Dense(1, activation='sigmoid',use_bias=True)(output)\n",
    "        print(\"这是一个二分类模型\")\n",
    "    else:\n",
    "        raise Exception(\"类别错误\")\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_list, outputs=output, name='multi_textcnn')\n",
    "\n",
    "    if tag_size > 2:\n",
    "        metric_list = [\n",
    "            tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "        ]\n",
    "        model.compile(\n",
    "            loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate,\n",
    "                clipnorm=1.0,\n",
    "                clipvalue=0.5,\n",
    "            ),\n",
    "            metrics = metric_list,\n",
    "        )\n",
    "    else:\n",
    "        metric_list = [\n",
    "            tf.keras.metrics.BinaryAccuracy(),\n",
    "            tf.keras.metrics.AUC(num_thresholds=10000)\n",
    "        ]\n",
    "        model.compile(\n",
    "            loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3,\n",
    "                clipnorm=1.0,\n",
    "                clipvalue=0.5,\n",
    "            ),\n",
    "            metrics = metric_list,\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gensim\n",
    "import os\n",
    "import LAC\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.utils\n",
    "\n",
    "APP_DIR  = os.path.dirname(os.path.realpath('__file__'))\n",
    "\n",
    "def trans_gensim_word2vec2tf_embedding(word2vector_file_path:str):\n",
    "    \"\"\"把gensim的word2vec结果转化为tf.keras.layers.Embedding需要的结果\n",
    "    \"\"\"\n",
    "\n",
    "    word2vec_model = gensim.models.Word2Vec.load(word2vector_file_path)\n",
    "\n",
    "    #所有的词\n",
    "    word_list = [word for word, word_info in word2vec_model.wv.vocab.items()]\n",
    "\n",
    "    #词到index的映射\n",
    "    word2index_dict = {\"<PADDING>\": 0, \"<UNK>\":1}\n",
    "\n",
    "    #保存特殊词的padding\n",
    "    specical_word_count = len(word2index_dict)\n",
    "\n",
    "    #词到词向量的映射\n",
    "    word2vector_dict = {}\n",
    "\n",
    "    #初始化embeddings_matrix\n",
    "\n",
    "    embeddings_matrix = np.zeros((len(word_list) + specical_word_count, word2vec_model.vector_size))\n",
    "    #初始化unk为-1,1分布\n",
    "    embeddings_matrix[word2index_dict[\"<UNK>\"]] = (1 / np.sqrt(len(word_list) + specical_word_count) * (2 * np.random.rand(word2vec_model.vector_size) - 1))\n",
    "\n",
    "    for i,word in enumerate(word_list):\n",
    "        #从0开始\n",
    "        word_index = i + specical_word_count\n",
    "        word2index_dict[str(word)] = word_index\n",
    "        word2vector_dict[str(word)] = word2vec_model.wv[word] # 词语：词向量\n",
    "        embeddings_matrix[word_index] = word2vec_model.wv[word]  # 词向量矩阵\n",
    "\n",
    "    #写入文件\n",
    "    with open(os.path.join(APP_DIR,\"data\",\"word2index.json\"),\"w\",encoding=\"utf8\") as f:\n",
    "        json.dump(word2index_dict,f,ensure_ascii=False)\n",
    "\n",
    "    return embeddings_matrix,word2vector_dict,word2index_dict\n",
    "\n",
    "\n",
    "def trans2index(word2index_dict,word):\n",
    "    \"\"\"转换\"\"\"\n",
    "    if word in word2index_dict:\n",
    "        return word2index_dict[word]\n",
    "    else:\n",
    "        if \"<UNK>\" in word2index_dict:\n",
    "            return word2index_dict[\"<UNK>\"]\n",
    "        else:\n",
    "            raise ValueError(\"没有这个值，请检查\")\n",
    "\n",
    "\n",
    "def trans_data2tf_data(data_file_path:str,x_max_length:int=None,word2index_dict=None):\n",
    "    \"\"\"把data文件转化为tf.data\n",
    "    \"\"\"\n",
    "\n",
    "    tag2index_dict = {}\n",
    "    tag_index_count = len(tag2index_dict)\n",
    "    lac = LAC.LAC(mode=\"seg\")\n",
    "\n",
    "    df = pd.read_csv(data_file_path)\n",
    "\n",
    "    x_list = []\n",
    "    for doc in df[\"content\"]:\n",
    "        word_list = lac.run(doc)\n",
    "        x_list.append([trans2index(word2index_dict,word) for word in word_list])\n",
    "    x_npa = np.array(x_list)\n",
    "\n",
    "    y_list = []\n",
    "    for tag in df[\"tag\"]:\n",
    "        tag = tag.strip()\n",
    "        if not (tag in tag2index_dict):\n",
    "            tag2index_dict[tag] = tag_index_count\n",
    "            tag_index_count += 1\n",
    "        y_list.append(tag2index_dict[tag])\n",
    "    y_npa = np.array(y_list,dtype=np.uint8)\n",
    "\n",
    "    print(\"x_list[:1]:{}\".format(x_list[:1]))\n",
    "    print(\"y_list[:1]:{}\".format(y_list[:1]))\n",
    "\n",
    "    #写入文件\n",
    "    with open(os.path.join(APP_DIR,\"data/tag2index.json\"),\"w\",encoding=\"utf8\") as f:\n",
    "        json.dump(tag2index_dict,f,ensure_ascii=False)\n",
    "\n",
    "    if not x_max_length:\n",
    "        x_max_length0 = np.max(np.array([len(v) for v in x_list]))\n",
    "        x_max_length = int(np.max(np.percentile(np.array([len(v) for v in x_list]),99.7)))\n",
    "        print(\"数据集中最长的句子长度为:{},设定的最长的句子长度为:{}\".format(x_max_length0,x_max_length))\n",
    "\n",
    "    x_npa = tf.keras.preprocessing.sequence.pad_sequences(x_npa,maxlen=x_max_length,dtype=np.int32,truncating=\"post\", padding='post',value=0)\n",
    "\n",
    "    x_npa,y_npa = sklearn.utils.shuffle(x_npa,y_npa,random_state=0)\n",
    "    print(\"x_npa[:1]:{}\".format(x_npa[:1]))\n",
    "    print(\"y_npa[:1]:{}\".format(y_npa[:1]))\n",
    "    print(\"x_npa.shape = {}\".format(x_npa.shape))\n",
    "    print(\"y_npa.shape = {}\".format(y_npa.shape))\n",
    "\n",
    "    return x_npa,y_npa,tag2index_dict\n",
    "\n",
    "\n",
    "\n",
    "def trans_tokenize_data2tf_data(data_file_path:str,x_max_length:int=None,word2index_dict=None):\n",
    "    \"\"\"把已经分好词的data文件转化为tf.data\n",
    "    \"\"\"\n",
    "\n",
    "    tag2index_dict = {}\n",
    "    tag_index_count = len(tag2index_dict)\n",
    "    lac = LAC.LAC(mode=\"seg\")\n",
    "\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    with open(data_file_path) as f:\n",
    "        for line in f:\n",
    "            temp_dict = json.loads(line.strip())\n",
    "            word_list = temp_dict[\"content_tokenize\"]\n",
    "            tag = temp_dict[\"tag\"].strip()\n",
    "            if not (tag in tag2index_dict):\n",
    "                tag2index_dict[tag] = tag_index_count\n",
    "                tag_index_count += 1\n",
    "            x_list.append([trans2index(word2index_dict,word) for word in word_list])\n",
    "            y_list.append(tag2index_dict[tag])\n",
    "    x_npa = np.array(x_list)\n",
    "    y_npa = np.array(y_list,dtype=np.uint8)\n",
    "\n",
    "    print(\"x_list[:1]:{}\".format(x_list[:1]))\n",
    "    print(\"y_list[:1]:{}\".format(y_list[:1]))\n",
    "\n",
    "    #写入文件\n",
    "    with open(os.path.join(APP_DIR,\"data/tag2index.json\"),\"w\",encoding=\"utf8\") as f:\n",
    "        json.dump(tag2index_dict,f,ensure_ascii=False)\n",
    "\n",
    "    if not x_max_length:\n",
    "        x_max_length0 = np.max(np.array([len(v) for v in x_list]))\n",
    "        x_max_length = int(np.max(np.percentile(np.array([len(v) for v in x_list]),99.7)))\n",
    "        print(\"数据集中最长的句子长度为:{},设定的最长的句子长度为:{}\".format(x_max_length0,x_max_length))\n",
    "\n",
    "    x_npa = tf.keras.preprocessing.sequence.pad_sequences(x_npa,maxlen=x_max_length,dtype=np.int32,truncating=\"post\", padding='post',value=0)\n",
    "\n",
    "    x_npa,y_npa = sklearn.utils.shuffle(x_npa,y_npa,random_state=0)\n",
    "    print(\"x_npa[:1]:{}\".format(x_npa[:1]))\n",
    "    print(\"y_npa[:1]:{}\".format(y_npa[:1]))\n",
    "    print(\"x_npa.shape = {}\".format(x_npa.shape))\n",
    "    print(\"y_npa.shape = {}\".format(y_npa.shape))\n",
    "\n",
    "    return x_npa,y_npa,tag2index_dict\n",
    "\n",
    "\n",
    "def trans_multi_input_tokenize_data2npa(data_file_path:str,x_max_length:int=None,word2index_dict=None):\n",
    "    \"\"\"把已经分好词的data文件转化为tf.data , 多输入版本\n",
    "    \"\"\"\n",
    "\n",
    "    tag2index_dict = {}\n",
    "    tag_index_count = len(tag2index_dict)\n",
    "\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    with open(data_file_path) as f:\n",
    "        for line in f:\n",
    "            temp_dict = json.loads(line.strip())\n",
    "            text_tokenize_list = temp_dict[\"all_content_tokenize\"]\n",
    "            tag = temp_dict[\"tag\"].strip()\n",
    "            if not (tag in tag2index_dict):\n",
    "                tag2index_dict[tag] = tag_index_count\n",
    "                tag_index_count += 1\n",
    "            x_list.append([[trans2index(word2index_dict,word) for word in word_list] for word_list in text_tokenize_list])\n",
    "            y_list.append(tag2index_dict[tag])\n",
    "    y_npa = np.array(y_list,dtype=np.uint8)\n",
    "\n",
    "    print(\"x_list[:1]:{}\".format(x_list[:1]))\n",
    "    print(\"y_list[:1]:{}\".format(y_list[:1]))\n",
    "\n",
    "    #写入文件\n",
    "    with open(os.path.join(APP_DIR,\"data/tag2index.json\"),\"w\",encoding=\"utf8\") as f:\n",
    "        json.dump(tag2index_dict,f,ensure_ascii=False)\n",
    "\n",
    "    if not x_max_length:\n",
    "        x_max_length0 = np.max(np.array([len(v) for v in x_list]))\n",
    "        x_max_length = int(np.max(np.percentile(np.array([len(v) for v in x_list]),99.7)))\n",
    "        print(\"数据集中最长的句子长度为:{},设定的最长的句子长度为:{}\".format(x_max_length0,x_max_length))\n",
    "    \n",
    "    for i in range(len(x_list)):\n",
    "        x_list[i] = tf.keras.preprocessing.sequence.pad_sequences(x_list[i],maxlen=x_max_length,dtype=np.int32,truncating=\"post\", padding='post',value=0)\n",
    "    x_npa = np.array(x_list,dtype=np.int32)\n",
    "\n",
    "    x_npa,y_npa = sklearn.utils.shuffle(x_npa,y_npa,random_state=0)\n",
    "    print(\"x_npa[:1]:{}\".format(x_npa[:1]))\n",
    "    print(\"y_npa[:1]:{}\".format(y_npa[:1]))\n",
    "    print(\"x_npa.shape = {}\".format(x_npa.shape))\n",
    "    print(\"y_npa.shape = {}\".format(y_npa.shape))\n",
    "\n",
    "    return x_npa,y_npa,tag2index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_list[:1]:[[[1696, 18263, 2351, 433, 11, 19592, 12277, 689, 1711, 129, 0, 1, 5936, 5432, 9802, 112, 3533, 112, 1, 112, 3533, 112, 28247, 44095, 427, 18, 1, 11, 137, 12487, 485, 4979, 483, 485, 13348, 19592, 12277, 6124, 5013, 149, 491, 493, 8, 162, 495, 4256, 432, 11, 22112, 19592, 12277, 22112, 112, 850, 6498, 7913, 244, 1, 5831, 72257, 18, 483, 2705, 495, 895, 9837, 52992, 11, 234, 19592, 41044, 8, 6405, 283, 9786, 1552, 81, 27893, 11, 1732, 7727, 1538, 237, 483, 485, 13348, 19592, 12277, 6124, 5013, 149, 491, 493, 8, 162, 495, 67, 55, 741, 4355, 12, 18394, 81, 4488, 8, 944, 1400, 186, 2292, 57, 8, 162, 18, 4326, 7143, 2, 1, 47559, 475, 2388, 11, 19592, 12277, 1696, 283, 9786, 1552, 81, 27893, 433, 11, 1087, 3191, 1688, 18394, 8, 283, 1696, 223, 1083, 20144, 11, 32, 6, 1566, 19592, 12277, 750, 8, 810, 25507, 18, 1696, 18263, 1699, 179, 27893, 2582, 54, 1675, 325, 650, 1, 1696, 7968, 9786, 1281, 1322, 1494, 179, 1, 1, 1, 8, 483, 1, 495, 109, 53455, 162, 11, 46654, 1696, 81, 28746, 11, 1, 3613, 211, 230, 111, 11, 84, 34, 19592, 41044, 7968, 9786, 572, 358, 1494, 179, 51293, 6309, 18, 25629, 11, 12487, 237, 8, 483, 485, 1, 495, 162, 2, 19592, 12277, 8, 1696, 1322, 2718, 1657, 241, 8, 1696, 11, 1229, 16925, 243, 65, 2574, 1232, 8, 1175, 165, 1378, 1978, 11, 991, 1688, 4845, 211, 241, 6333, 10185, 8, 8570, 18, 1538, 5976, 11, 12487, 237, 483, 485, 13348, 19592, 12277, 6124, 5013, 149, 491, 493, 8, 162, 495, 11, 741, 2468, 2444, 8, 55, 944, 1400, 186, 2292, 57, 7727, 129, 55, 8570, 1696, 57, 2, 55, 12277, 533, 15987, 8, 1696, 160, 948, 47943, 1696, 4355, 11, 37660, 24838, 16519, 4631, 15987, 8, 1696, 6026, 6567, 8, 11, 16925, 51841, 439, 313, 12277, 533, 15987, 8, 1696, 1, 1696, 18394, 11, 211, 818, 8, 6567, 15987, 23241, 313, 16519, 24838, 37660, 7865, 724, 6026, 8, 1, 1696, 18394, 818, 8, 6567, 8, 11, 16925, 51841, 439, 18, 57, 36697, 11, 319, 256, 8, 4488, 1696, 54, 1403, 8367, 8, 11, 448, 3613, 3145, 10026, 50, 1763, 267, 8, 20161, 165, 18, 2462, 8, 3524, 109, 2213, 50, 7740, 1696, 111, 2760, 11753, 1879, 2799, 7740, 19625, 15834, 793, 2034, 11, 2497, 3029, 98, 2787, 3145, 10026, 50, 1763, 267, 8, 20161, 165, 18, 23308, 11, 461, 1841, 2405, 3524, 522, 179, 4154, 11, 234, 1, 2351, 5540, 3524, 11, 4023, 19592, 12277, 1696, 283, 9786, 127, 65, 1403, 3524, 7740, 8, 8570, 1687, 2845, 1552, 18, 4631, 4981, 7141, 1217, 24122, 183, 8, 104, 11, 1, 2213, 50, 93, 1017, 3524, 81, 2093, 11, 341, 1768, 19592, 12277, 1696, 283, 9786, 1688, 362, 211, 27893, 18, 5366, 11, 114626, 6997, 82, 1, 28977, 1, 257, 11, 55, 112, 3595, 162, 11, 336, 54, 3015, 129, 378, 379, 42130, 387, 1019, 82, 19592, 41044, 6405, 283, 8, 796, 1, 82, 50, 866, 1553, 54759, 461, 12, 1232, 8, 1623, 162, 164, 1486, 18, 57, 8089, 1173, 1, 11, 805, 36, 8, 4355, 6870, 656], [4495, 11643, 11, 17079, 2196, 865, 2754, 30014, 1993, 0, 31305, 1518, 21201, 2, 1, 109, 7752, 2, 1, 15053, 111, 11, 9802, 2, 1, 11, 30268, 2, 1, 82, 1, 11, 41389, 6177, 2, 483, 4495, 11643, 11, 17079, 2196, 1, 30014, 86437, 112, 1, 1993, 2, 26295, 2178, 1, 495, 11, 22136, 7621, 1518, 2, 28247, 155, 877, 65512, 12, 112, 4490, 112, 11541, 3873, 11, 1583, 284, 8800, 4016, 129, 18, 4552, 11, 5542, 54, 244, 8314, 9264, 11, 17079, 2361, 89223, 467, 68643, 237, 129, 1489, 9614, 865, 2754, 30014, 112, 74020, 112, 86437, 112, 593, 112, 345, 8, 12161, 2946, 19735, 112, 74020, 112, 86437, 112, 1, 82, 86437, 112, 1, 82, 86437, 112, 1, 18, 55, 3550, 4495, 2502, 31452, 11, 89222, 2706, 112, 32116, 112, 7066, 35741, 8, 3574, 11, 57, 89223, 11420, 18, 55, 88, 2706, 82, 9903, 4650, 2763, 82, 48397, 82, 3006, 82, 21974, 82, 1, 112, 107531, 82, 1, 82, 17924, 82, 27132, 82, 1761, 12, 1845, 7829, 7829, 112, 272, 244, 888, 3880, 49107, 112, 32116, 112, 8, 4495, 11, 16, 196, 129, 2358, 1535, 18, 57, 36810, 2, 1, 100517, 6750, 14157, 433, 37, 12794, 18, 485, 6663, 237, 11, 2926, 6695, 37, 1839, 72, 7260, 8085, 18, 991, 7490, 1519, 7433, 8, 2679, 112, 74020, 112, 86437, 112, 593, 112, 345, 8, 4495, 514, 7740, 18, 1964, 6323, 68495, 8, 54694, 2679, 11, 514, 112, 1, 112, 16895, 2885, 11, 991, 4011, 1864, 129, 4943, 18, 84, 112, 1, 112, 689, 54, 112, 32116, 112, 67, 8, 1, 11, 89223, 39, 472, 81, 112, 1, 109, 93731, 112, 1, 111, 18, 2120, 1, 32116, 8, 9926, 622, 127, 3493, 146, 244, 129, 17079, 34, 2241, 98, 2, 8920, 2196, 112, 32116, 244, 4364, 2310, 82, 51603, 19906, 8, 1622, 1, 433, 11, 89223, 8866, 88, 36079, 100517, 6750, 8, 1, 433, 11, 6638, 129, 129, 8483, 112, 86437, 112, 1, 11, 819, 752, 2826, 112, 1, 112, 345, 18, 33430, 11, 74020, 112, 86437, 112, 593, 112, 345, 12171, 5181, 129, 112, 32116, 112, 753, 8, 5098, 55, 1247, 57, 2, 2752, 9361, 112, 1, 112, 1, 112, 1, 8, 5558, 24778, 1861, 313, 1676, 439, 112, 1, 112, 18711, 112, 8, 112, 32116, 11, 8483, 30014, 2254, 196, 112, 1, 112, 906, 26737, 1010, 112, 1, 112, 5558, 313, 1676, 439, 112, 1, 112, 1, 8, 3092, 112, 32116, 11, 196, 741, 689, 2570, 8, 14548, 44627, 2542, 19843, 8, 1, 18, 274, 1, 8, 112, 74020, 112, 86437, 112, 1, 11, 1537, 2502, 358, 88, 1, 1763, 15465, 18, 86437, 112, 1, 112, 54, 5223, 5061, 112, 37262, 112, 5558, 112, 32116, 18, 6870, 6494, 112, 37262, 325, 244, 17079, 4628, 11, 19843, 8, 1307, 1588, 1840, 13170, 682, 2468, 3549, 1, 11, 1840, 13976, 4009, 57741, 892, 60880, 8, 5558, 12477, 11, 1553, 1840, 7484, 2468, 7807, 11, 9352, 42208, 82, 70161, 1, 12, 33169, 34075, 18, 5548, 30014, 689, 20321, 112, 1, 112, 345, 11, 1306, 98, 9614, 55, 249, 66, 148, 57, 8, 63226, 30014, 112, 74020, 112, 86437, 112, 1, 112, 1], [73706, 6870, 1046, 3289, 325, 0, 31305, 1518, 10361, 13527, 2, 1, 871, 401, 109, 7752, 2, 1, 111, 11, 9802, 2, 235, 1, 82, 1, 11, 22136, 7621, 1518, 2, 28247, 11172, 11, 8377, 1623, 55, 11437, 73706, 57, 8, 4151, 11, 244, 3712, 98, 5831, 129, 2119, 8, 32225, 18, 4892, 8, 29015, 54, 3869, 38204, 244, 1320, 98, 18635, 692, 129, 11437, 8, 73706, 343, 11, 1, 7697, 1952, 1, 11, 3520, 245, 19400, 18, 21560, 38204, 10539, 2, 13949, 12982, 8, 1, 1, 1964, 325, 346, 6522, 55, 1, 57, 8, 493, 11, 1, 45836, 46493, 18, 13955, 244, 3440, 346, 3237, 256, 11, 3236, 5473, 55, 4713, 1711, 57, 55, 378, 37, 1, 57, 11, 52532, 67, 129, 11552, 13291, 8, 5532, 11, 22112, 11437, 73706, 22112, 6498, 244, 4151, 445, 14195, 2258, 8, 11129, 151, 11, 211, 95712, 401, 11, 689, 520, 1484, 535, 19758, 8, 55, 24070, 9565, 57, 3415, 26183, 179, 129, 5695, 25672, 18, 475, 82, 73706, 37, 463, 3289, 325, 21, 34, 1090, 1, 8, 1928, 1244, 896, 1, 11, 2034, 129, 877, 895, 8, 1928, 5971, 18098, 967, 50, 11, 73706, 2376, 3160, 1, 18, 991, 34, 1928, 14486, 73706, 8, 796, 1333, 1507, 18, 87151, 11, 34, 88, 4144, 2830, 129, 34728, 73706, 9656, 11, 991, 73706, 22709, 1731, 3289, 129, 11, 74522, 73706, 358, 6207, 1, 11, 633, 8475, 141, 1928, 781, 244, 654, 2760, 1, 30080, 8, 1, 18, 28127, 16899, 11, 73706, 7063, 819, 244, 980, 31812, 6740, 18, 8475, 11, 65136, 16117, 36753, 2178, 248, 52188, 1, 483, 1, 495, 8, 1, 2330, 11, 244, 716, 7913, 8156, 50, 18, 147, 11, 3155, 698, 1326, 2283, 2283, 20204, 8, 1, 82, 1, 8, 1, 82, 1, 8, 1, 12, 1, 8, 91071, 11, 127, 7156, 191, 34, 50, 18, 333, 11, 2010, 235, 352, 6758, 116, 12, 1928, 3767, 396, 7285, 8, 120, 1307, 11, 73706, 82, 1, 82, 1, 244, 34, 50, 8, 17360, 120, 1307, 11, 131, 73706, 8, 17360, 724, 1239, 178, 11, 341, 155, 1360, 1928, 396, 3288, 54, 24466, 8, 8358, 18, 991, 1346, 16505, 650, 1076, 198, 414, 1138, 1, 279, 8, 4889, 11, 73706, 8820, 4668, 967, 819, 129, 1235, 8, 55, 865, 557, 57, 3413, 18, 21, 22283, 8, 73706, 11, 1041, 741, 52048, 622, 81, 2970, 11, 1322, 12629, 1, 73706, 109, 1138, 10275, 36678, 111, 82, 1, 73706, 109, 10275, 8933, 27973, 36678, 111, 12, 5476, 73706, 109, 1657, 27973, 36678, 111, 18, 27162, 1054, 2, 7621, 67, 8, 55, 1, 57, 1634, 81, 55, 1, 57, 7567, 3498, 1928, 8, 1, 81, 21573, 11, 13978, 90, 2288, 4846, 11, 12542, 1894, 2909, 4846, 6744, 9569, 73706, 11, 1046, 21560, 1928, 4843, 976, 654, 1, 1, 83, 95, 1, 1964, 73706, 18, 741, 1, 1894, 8733, 10275, 82, 14277, 1964, 73706, 1894, 8733, 26520, 1242, 11, 341, 7744, 1928, 4843, 976, 21396, 41265, 11, 4228, 1, 4108, 81, 6550, 11, 3192, 2679, 64519, 18, 1041, 6744, 33232, 2542, 82, 73706, 622, 689, 3289, 82, 1, 7761, 11, 21396, 6927, 2542, 18, 2883], [48001, 3560, 8, 4467, 4216, 1, 129, 325, 0, 1061, 3560, 8, 4467, 68810, 9805, 4216, 11, 8866, 40, 55, 535, 57, 1, 129, 18, 496, 11, 4680, 244, 20371, 1211, 67, 675, 11, 5223, 2336, 2678, 274, 1728, 8, 69697, 4216, 472, 475, 2283, 2283, 63051, 514, 85949, 748, 3383, 527, 2336, 8, 93058, 76, 1, 883, 8134, 235, 899, 8018, 18, 125, 1211, 10199, 11, 874, 2183, 6799, 11, 34, 514, 6715, 13, 25121, 7154, 8, 6070, 1036, 810, 32, 4250, 21110, 4918, 8, 873, 313, 118, 11, 125, 4216, 1036, 1333, 11535, 10458, 4216, 2793, 403, 18, 12571, 11, 341, 475, 2648, 6949, 2317, 325, 63051, 8, 68810, 4216, 1489, 2678, 1673, 7000, 325, 855, 4250, 1, 129, 325, 1322, 4962, 8, 54, 11, 63051, 8, 108379, 6930, 245, 4631, 659, 25578, 6715, 1648, 4250, 4918, 18, 8590, 244, 7032, 6715, 2675, 1, 15290, 646, 11, 112864, 109, 1, 111, 724, 514, 63051, 15, 527, 11, 4799, 2971, 514, 1, 8, 1583, 774, 3383, 17023, 244, 17319, 148, 235, 95419, 819, 4250, 4918, 11, 448, 886, 1281, 244, 762, 2301, 3718, 21110, 774, 18, 1047, 2454, 11, 125, 784, 234, 128, 6715, 3812, 71571, 4250, 4918, 18, 2205, 13063, 11, 1, 414, 1056, 257, 2, 55, 1041, 4216, 535, 3765, 403, 11, 1046, 762, 47323, 4645, 244, 6715, 45, 4368, 11, 1280, 5909, 3789, 1083, 27443, 308, 1, 18, 57, 21421, 54, 12669, 6, 11661, 188, 23692, 17867, 8, 3015, 11, 127, 1, 6715, 1273, 6, 1, 8, 2888, 18, 1537, 11, 341, 514, 63051, 2816, 1, 514, 6715, 3356, 8, 9154, 3093, 127, 1, 18, 1, 35611, 3332, 17852, 78001, 11, 1, 1056, 244, 1, 1982, 6858, 11, 38244, 129, 6715, 61224, 18, 12571, 1437, 4195, 1076, 433, 11, 6715, 33542, 9034, 821, 2775, 11, 341, 7964, 4216, 55, 14, 1743, 34, 571, 715, 25578, 6715, 57, 11, 84, 1, 244, 4716, 164, 335, 6695, 18300, 18, 4680, 244, 1211, 67, 414, 2294, 11, 10470, 11, 1, 244, 8604, 67, 31, 129, 341, 475, 6166, 11, 448, 257, 12552, 3585, 125, 527, 11, 234, 4799, 7870, 308, 10458, 4216, 8907, 47217, 18, 40, 244, 14984, 11, 6715, 724, 8127, 514, 1, 69377, 12, 25182, 109, 514, 87304, 2799, 3850, 111, 4194, 11, 741, 395, 6715, 71571, 8, 1440, 18, 43892, 234, 63051, 12, 6715, 527, 4779, 8, 874, 8221, 81, 55, 34, 1, 78, 8, 1, 57, 11, 448, 39, 341, 54, 1, 244, 255, 67, 1145, 10199, 8, 18, 1727, 2641, 22818, 234, 3645, 9692, 81, 32037, 1032, 2585, 8, 69045, 18, 5366, 11, 63051, 244, 11519, 237, 705, 4169, 39, 11, 1, 514, 103, 8, 527, 7631, 4779, 313, 4178, 6923, 6924, 148, 11, 103, 6874, 7631, 254, 24, 485, 4216, 244, 6715, 4250, 4918, 850, 8, 255, 18, 280, 244, 623, 4628, 11, 346, 527, 12621, 54, 9120, 129, 18, 991, 18715, 514, 6715, 8, 527, 4779, 11, 1588, 6, 63051, 8, 4250, 21110, 679, 1482, 1603, 810, 14248, 325, 7781, 4978, 18, 496, 11, 63051, 20480, 55823, 244, 2113, 1303, 1380, 2898, 98, 127, 3899, 11, 103, 4, 514, 463, 464, 461, 2799], [5374, 49601, 40016, 8, 1, 2, 1235, 534, 433, 11, 4954, 99, 81, 3982, 0, 31305, 1518, 21201, 2, 1, 109, 7752, 2, 1, 111, 11, 9802, 2, 1, 11, 22136, 7621, 1518, 2, 28247, 1, 112, 67201, 1952, 26221, 11, 244, 40016, 98, 4036, 1, 26464, 11, 1076, 198, 2068, 1, 11, 3755, 4761, 3651, 244, 4648, 6938, 523, 98, 1646, 62927, 12, 57200, 8, 3434, 3793, 472, 475, 11, 2883, 39743, 6, 40016, 248, 129, 1278, 11, 991, 1, 9449, 19584, 1273, 3870, 40016, 18, 55, 272, 54, 2333, 1449, 9802, 11, 54, 272, 8, 1, 7063, 1840, 272, 135, 28476, 18, 1041, 40016, 3613, 654, 11, 378, 414, 1322, 4274, 899, 523, 1882, 3902, 13263, 18, 57, 1, 271, 18, 1, 112, 67201, 24385, 40016, 244, 5374, 11, 40016, 12, 39907, 164, 34, 4648, 6938, 732, 535, 7206, 445, 8454, 90, 11, 5374, 1866, 414, 84496, 55, 62076, 57, 6746, 13789, 8, 40016, 11, 12816, 8, 5374, 2574, 1, 6938, 343, 40, 819, 7727, 40016, 244, 1866, 21141, 8, 761, 18, 244, 341, 9847, 16861, 67, 11, 77327, 8, 1, 99278, 332, 4648, 6938, 523, 11, 741, 7621, 1193, 30340, 5374, 4396, 10385, 67, 40016, 12637, 8, 1764, 18, 244, 47139, 8, 1278, 333, 11, 12528, 8594, 148, 11, 4396, 2641, 523, 1, 332, 129, 1, 82, 5374, 895, 7948, 8643, 1, 332, 129, 1, 82, 353, 19907, 523, 1, 332, 129, 47552, 18, 5374, 13176, 71, 2773, 127, 22917, 54717, 341, 11413, 12263, 11, 11535, 78592, 82, 1, 164, 343, 127, 244, 16220, 148, 7913, 19709, 129, 2853, 1866, 18, 12139, 11535, 1, 112, 1, 12, 1, 3595, 8590, 1726, 40, 819, 254, 50, 96251, 8, 343, 11, 349, 48917, 29977, 18, 1866, 11602, 234, 2120, 343, 11112, 6740, 11, 13989, 1481, 14500, 5374, 458, 8, 14501, 11, 157, 43188, 127, 1, 18, 55, 1, 2283, 1, 8, 4648, 6938, 732, 3533, 5374, 458, 57, 55, 1, 2283, 5374, 21613, 4648, 6938, 732, 57, 55, 1, 2283, 5374, 2223, 8, 6938, 732, 57, 55, 78592, 2283, 5374, 458, 8, 4648, 6938, 732, 57, 55, 1, 112, 1, 2283, 5374, 458, 8, 4648, 6938, 732, 57, 55, 47552, 2283, 5374, 458, 3533, 4648, 6938, 732, 57, 18, 1, 24385, 1, 2883, 2120, 4648, 6938, 523, 127, 77327, 1646, 129, 1226, 534, 11, 991, 1960, 55, 11597, 40016, 57, 415, 863, 8, 267, 11126, 11, 84, 12690, 8, 1, 6949, 2787, 7636, 893, 179, 25, 11, 127, 9041, 650, 271, 2720, 11492, 18, 10, 107, 1, 12, 1, 8, 49896, 5374, 5397, 1, 112, 1, 271, 11, 55, 244, 346, 466, 11, 5306, 1327, 415, 10499, 179, 16190, 1956, 3638, 2720, 2492, 18, 57, 2120, 5374, 32006, 732, 260, 25740, 21, 414, 77565, 11, 244, 7627, 1646, 8, 1, 15166, 151, 2229, 11, 12795, 12690, 8, 1, 18, 1, 112, 1, 244, 1, 8, 793, 1, 81, 10031, 11, 47552, 8, 1866, 1, 88, 50207, 40, 1239, 129, 1, 127, 88, 40016, 1708, 7206, 433, 8082, 2068, 6368, 8, 1, 11, 244, 8594, 90, 148, 15290, 21564, 308, 309, 18, 1, 99, 81, 3982, 3550, 54, 41838, 2502, 25965, 343, 11, 78592, 82, 1, 112], [3057, 514, 3428, 11, 508, 550, 1673, 14060, 1744, 325, 0, 4548, 274, 8772, 8, 103, 1036, 54, 114362, 129, 11, 6725, 2827, 182, 8, 103, 11, 12949, 50, 1280, 182, 433, 358, 1730, 7824, 18311, 7827, 11, 6923, 6867, 467, 2113, 12, 2588, 7314, 129, 182, 2598, 11, 6, 7824, 18311, 8, 1252, 1333, 1002, 11, 520, 328, 1252, 98, 7674, 129, 29654, 11, 3595, 8, 1252, 234, 211, 12515, 82, 8505, 82, 5973, 164, 5108, 508, 644, 11, 14376, 1, 109, 7827, 896, 26919, 111, 18, 244, 2881, 466, 11, 260, 514, 114362, 1, 475, 1, 81051, 8, 11, 127, 1952, 3057, 1264, 8, 2881, 550, 129, 18, 2883, 9119, 514, 6867, 37, 1540, 11, 991, 1041, 271, 29239, 141, 14060, 2964, 260, 6, 6867, 2034, 975, 11, 127, 1952, 3057, 2881, 18, 762, 5208, 11, 535, 625, 54, 33839, 44865, 8, 20271, 6446, 82, 3895, 3539, 23467, 11, 28348, 540, 8121, 20271, 11, 44287, 3057, 3539, 1270, 1271, 18, 341, 88, 17316, 8716, 129, 3057, 2881, 6, 525, 2502, 37, 2497, 8, 3927, 18, 137, 6867, 182, 558, 417, 11, 1553, 1252, 8, 1555, 11, 50, 2648, 624, 625, 341, 155, 3057, 1460, 54, 464, 551, 11, 1630, 3057, 2881, 2279, 6867, 11, 127, 1588, 37, 691, 17744, 18, 40602, 1327, 625, 11, 244, 1252, 98, 11, 3057, 508, 550, 3008, 514, 2954, 1090, 2707, 1535, 18, 1015, 272, 31316, 5867, 7491, 2, 3057, 2881, 23560, 1819, 550, 11, 1318, 7000, 325, 691, 2405, 6867, 805, 54, 1675, 1535, 11, 514, 114362, 1, 6949, 2317, 325, 1, 172, 54, 6867, 8, 2901, 311, 887, 3057, 2881, 550, 21, 7631, 3092, 11, 428, 770, 39725, 1716, 11, 3057, 234, 2881, 514, 71, 70, 8, 102, 26672, 244, 402, 845, 6836, 67, 12184, 13008, 11, 336, 2350, 6026, 82, 3771, 83, 899, 2881, 70, 1553, 6525, 8, 172, 18, 770, 11, 1, 514, 71, 70, 196, 172, 1, 11, 244, 2168, 67, 8, 3648, 81, 6560, 18, 3057, 12184, 1464, 129, 6525, 770, 8, 172, 11, 81, 9657, 18, 651, 7347, 770, 3057, 2881, 8, 172, 896, 81, 14233, 18, 21497, 11, 114362, 770, 172, 81, 1, 11, 1999, 81, 1, 18, 3057, 2881, 8, 172, 896, 54, 6867, 8, 2901, 311, 887, 18, 114362, 770, 2709, 172, 3719, 762, 800, 11, 3057, 2881, 83, 71, 70, 550, 172, 81, 1, 11, 221, 116, 896, 81, 40178, 313, 12771, 81, 1, 11, 221, 116, 896, 1, 18, 741, 6525, 770, 244, 2881, 514, 71, 70, 1379, 67, 1565, 1306, 67773, 2990, 7347, 11, 3057, 2881, 550, 800, 172, 896, 81, 60605, 18, 21497, 11, 114362, 800, 172, 1, 11, 1999, 114457, 18, 3057, 2881, 172, 54, 6867, 8, 5565, 11, 2405, 429, 8, 1687, 2901, 311, 887, 1294, 2784, 18, 6303, 1322, 625, 11, 244, 172, 335, 11, 3057, 2881, 54, 6867, 8, 2901, 311, 887, 18, 341, 6, 3057, 3873, 54, 464, 1322, 254, 8, 3901, 18, 1630, 3057, 2881, 32840, 8, 1900, 514, 6867, 188, 362, 2885, 11, 550, 1379, 127, 2939, 6867, 18991, 18, 3057, 2881, 8, 550, 1322, 43988, 54, 6867, 8, 1, 3057, 2881, 37, 1819, 550], [8156, 7768, 3712, 11, 378, 9459, 2223, 54, 464, 16077, 18677, 0, 31305, 1518, 21201, 2, 15594, 691, 109, 7752, 2, 1, 111, 11, 9802, 2, 1, 11, 22136, 7621, 1518, 2, 28247, 8156, 1, 11, 22283, 11602, 8263, 1583, 12, 34, 13063, 1, 8, 461, 129, 18, 88, 8528, 44361, 82, 1598, 470, 82, 352, 14289, 7829, 7829, 31901, 10062, 63692, 3712, 8, 2119, 3564, 11, 34, 12, 7768, 8, 1, 11, 71639, 1306, 1, 13014, 4511, 129, 2896, 1583, 74252, 18, 5542, 54, 9210, 461, 11, 7066, 2760, 41202, 15264, 6090, 27942, 489, 313, 88, 14583, 91, 11, 7768, 9770, 129, 112, 22443, 112, 464, 7188, 12, 112, 100, 112, 464, 15211, 11, 687, 7188, 37556, 476, 514, 4373, 313, 5282, 335, 11, 7768, 3344, 112, 100, 112, 2376, 20357, 82, 2909, 112, 2376, 40944, 82, 887, 112, 2376, 15541, 8, 29660, 489, 11, 483, 1, 495, 12, 483, 5133, 495, 127, 1056, 146, 244, 20358, 75636, 67, 313, 7768, 42046, 2896, 34, 8, 38111, 42046, 2784, 11, 1, 127, 1, 1, 7829, 7829, 63244, 244, 7768, 8, 45155, 98, 11, 1, 8479, 8, 4421, 11, 74642, 1840, 650, 1, 112, 7486, 112, 2376, 185, 18, 7768, 38111, 27164, 244, 1620, 98, 11, 7768, 12, 34, 22818, 37761, 11, 1, 1882, 11, 7066, 1, 1620, 9190, 389, 1, 8, 8479, 11278, 11, 330, 54, 20281, 1226, 51253, 113730, 18, 7768, 8, 15900, 54, 1, 1, 1, 494, 8, 11, 7768, 8, 1, 2679, 28765, 16278, 8, 1, 18, 7768, 1, 78371, 50416, 112, 2376, 11, 7768, 7063, 55997, 1, 26972, 18, 7768, 1, 65572, 1, 11, 26972, 66, 2679, 1, 18, 7768, 1, 16638, 67, 11, 26613, 74409, 112, 1, 112, 1, 11, 78509, 54, 1, 11, 29131, 74409, 112, 1, 112, 1, 11, 78509, 54, 1, 18, 7768, 59866, 654, 48044, 1, 472, 5585, 11, 7768, 59866, 1, 483, 1, 495, 483, 1, 495, 483, 1, 495, 83, 111208, 8, 483, 1, 495, 483, 1, 495, 164, 5432, 7066, 1964, 48044, 23754, 8, 18, 7768, 1, 98, 274, 17043, 8, 5432, 483, 1, 495, 11, 32, 5564, 1, 62863, 34, 1, 54509, 45788, 18, 1, 67, 37, 4765, 8, 48044, 3881, 11, 1, 6522, 1, 8, 1, 11, 514, 1, 8, 16329, 4450, 1259, 18, 97, 11, 1964, 7132, 1, 35024, 1, 1, 11, 1633, 1588, 1306, 1, 56133, 689, 58084, 18, 7768, 192, 1, 11, 4761, 14152, 21394, 129, 48930, 11, 633, 1335, 1, 54, 3067, 14152, 8, 18, 7768, 10610, 8089, 42396, 2201, 11661, 47122, 11, 43310, 54, 55, 46904, 15721, 1, 57, 11, 757, 6522, 1, 8, 55, 1, 57, 11, 1, 8773, 1, 109, 56237, 111, 82, 1, 109, 1, 111, 82, 99441, 109, 1, 111, 82, 1, 109, 1, 111, 82, 1, 109, 1, 111, 235, 2724, 11, 576, 12673, 1, 82, 1, 12, 7768, 1, 1, 81, 30752, 67, 1, 18, 538, 9399, 47122, 3251, 14586, 112, 1, 112, 6218, 42396, 11, 8989, 38161, 18, 346, 461, 1, 112, 7486, 112, 2376, 185, 8, 34, 11, 12795, 1583, 2468, 21988, 8, 37016, 1, 2, 2896, 28765, 1286, 67, 11, 543, 37, 2061, 1, 8, 16314], [241, 2011, 13888, 13888, 129, 6929, 325, 0, 7677, 27113, 908, 18090, 63532, 2333, 109, 1, 3591, 20677, 11, 7677, 51846, 2244, 63532, 111, 18, 835, 10764, 7050, 237, 4649, 129, 11, 272, 1882, 15747, 341, 131, 10026, 892, 8, 1226, 4310, 12, 1081, 18, 5061, 5867, 631, 463, 8, 54, 10189, 535, 43988, 95921, 8, 241, 11, 762, 800, 434, 13588, 37, 241, 8, 1372, 1086, 7066, 11236, 4180, 8, 174, 18, 341, 358, 321, 1467, 325, 3520, 174, 8, 4011, 1481, 11592, 11, 341, 54, 321, 7287, 8, 325, 241, 1379, 1588, 19208, 1582, 6929, 325, 1041, 1461, 241, 82, 20412, 11, 12166, 1088, 187, 1363, 8, 184, 1999, 376, 116, 7349, 18, 54, 1819, 126, 2787, 196, 631, 188, 8, 376, 116, 325, 3767, 25, 1322, 7000, 2175, 325, 1433, 54, 818, 2632, 2333, 54742, 11, 10916, 18, 434, 188, 241, 800, 2267, 11, 13861, 174, 13063, 55, 1, 57, 325, 1927, 11, 112, 1363, 67, 2120, 241, 8, 1460, 9449, 1731, 188, 8, 2657, 11, 50, 883, 13547, 540, 254, 129, 18, 2713, 11, 11753, 241, 174, 4011, 11592, 11, 341, 11989, 241, 8, 871, 2976, 11, 2267, 448, 44052, 2679, 1957, 25082, 24669, 9255, 8, 279, 11, 1727, 1322, 528, 18618, 8, 268, 244, 4131, 21143, 2418, 1674, 11654, 11, 9352, 5722, 6341, 463, 1226, 1999, 5539, 174, 313, 84, 241, 3356, 127, 1588, 9833, 33476, 18, 272, 9344, 362, 1855, 241, 11, 874, 2679, 244, 352, 1086, 177, 8, 2426, 11, 241, 54, 352, 8, 1, 11, 358, 1674, 1226, 55, 14337, 57, 18], [5602, 647, 16892, 11, 341, 40, 1882, 129, 325, 0, 5306, 6927, 726, 24040, 8, 4835, 6929, 325, 1, 185, 1726, 18071, 40, 107, 2720, 362, 11505, 1731, 2327, 11, 1006, 9603, 333, 689, 54, 77311, 188, 11778, 18, 6923, 11, 260, 1840, 5306, 726, 8, 1, 8, 353, 11, 3008, 2679, 16100, 8, 62524, 23194, 91143, 11, 638, 1, 550, 1400, 129, 11, 4894, 1378, 8, 343, 11, 5306, 1036, 1481, 13134, 362, 98, 47199, 18, 991, 392, 358, 271, 8, 54, 11, 3191, 1726, 11, 24040, 8, 2336, 48875, 54, 289, 8, 11, 10862, 107, 5445, 530, 514, 1043, 18, 2462, 11, 24040, 2348, 33039, 129, 16892, 248, 5434, 11, 448, 1865, 8234, 248, 129, 2105, 18, 1, 112, 1, 325, 24040, 8, 112, 1, 112, 52711, 345, 54, 6133, 8, 4110, 343, 11, 762, 800, 237, 129, 7168, 1944, 9082, 8, 52711, 112, 1050, 112, 433, 11, 1947, 8, 11038, 343, 2679, 5548, 16892, 248, 5434, 4835, 18, 3198, 11, 341, 736, 91143, 88, 62524, 638, 24040, 433, 11, 6541, 1643, 1898, 18, 5548, 9080, 895, 8, 26743, 11, 2679, 22151, 2105, 6149, 16892, 248, 17760, 8, 4844, 18, 40022, 112, 34991, 19845, 8, 17764, 5434, 15872, 244, 129, 4844, 7851, 11, 528, 1, 12609, 8, 4844, 456, 1882, 1, 11, 16, 196, 15262, 18, 15707, 112, 4844, 13441, 54, 362, 1, 8, 11, 24040, 22151, 4844, 8, 5579, 54, 11, 9903, 12609, 8, 1961, 56497, 11, 124, 3325, 19845, 148, 8, 1, 19845, 1, 81, 1961, 11, 1732, 196, 1, 11, 991, 341, 127, 40, 1768, 11, 2120, 14165, 54, 4266, 74, 8, 19845, 1228, 11, 535, 21849, 2418, 4266, 1, 129, 11, 4266, 74, 8, 19845, 1228, 11484, 2570, 129, 11, 74, 6245, 1, 5539, 1631, 810, 18, 84, 358, 196, 1682, 456, 74, 1682, 8, 682, 11, 414, 415, 3092, 8, 74, 2134, 82, 12609, 8, 4844, 2781, 82, 15644, 2418, 9496, 1845, 164, 2799, 3909, 18, 9129, 24040, 196, 129, 2105, 11, 26740, 129, 12689, 15006, 164, 456, 433, 11, 1, 4844, 8, 1, 2502, 4251, 17293, 8, 18, 244, 1, 5434, 12078, 11, 4844, 15157, 37516, 2427, 1535, 11, 63711, 112, 1, 112, 15707, 11, 178, 112, 1, 112, 74820, 11, 1, 112, 21641, 1943, 11, 80615, 112, 26737, 11, 1, 112, 26190, 1, 18, 7731, 54, 112, 44753, 11, 2122, 8, 3545, 112, 15059, 11, 346, 622, 2703, 5306, 29761, 112, 44743, 112, 127, 5197, 1036, 18, 20219, 335, 11, 84011, 112, 8430, 8, 23073, 12, 112, 1, 112, 116939, 8, 20639, 11, 12, 1, 710, 8, 5602, 647, 1, 11, 12171, 358, 14257, 129, 1226, 18, 15644, 335, 17765, 1, 5434, 11, 1, 112, 1, 11, 6822, 19845, 948, 62495, 11, 12062, 112, 1, 11, 12062, 112, 1, 11, 127, 348, 54, 2427, 1535, 18, 622, 335, 11, 24040, 112, 1, 112, 266, 129, 2946, 9698, 1412, 2, 1316, 4255, 49923, 112, 1, 112, 6558, 11, 2288, 4255, 49923, 112, 94408, 112, 6558, 11, 2288, 4255, 24863, 112, 1, 112, 6558, 18, 8234, 2105, 12185, 54, 5309, 13066, 59371, 8, 5284, 472, 475, 11, 21421, 530, 1036, 318, 1226, 7168, 12797, 18], [37016, 42363, 2, 204, 12548, 14195, 11, 1460, 38270, 0, 13097, 4563, 27162, 188, 871, 5936, 9802, 1, 112, 1, 3025, 182, 433, 29892, 2271, 4131, 433, 11, 42363, 8, 7827, 1589, 81114, 98, 129, 796, 5775, 18, 62539, 180, 11, 42363, 237, 4719, 3049, 10764, 11, 4131, 104, 74, 11, 800, 1, 196, 198, 1, 11, 6007, 88806, 18, 4131, 257, 11, 341, 336, 54, 55, 119, 68810, 30233, 5299, 11577, 6, 8123, 550, 1482, 1483, 810, 4935, 57, 18, 805, 429, 806, 11, 42363, 8, 2168, 221, 2716, 5560, 11, 1999, 88, 429, 8, 65308, 32740, 6007, 88806, 11, 223, 211, 9515, 18, 5299, 2703, 9814, 126, 3787, 8, 3511, 54, 14922, 8, 18, 8590, 244, 1060, 2694, 11, 42363, 40, 724, 237, 1372, 3261, 11, 39, 1280, 800, 198, 221, 174, 896, 230, 82, 6007, 11144, 1181, 11846, 308, 212, 13, 2283, 2283, 10764, 16, 74, 2271, 19527, 514, 1372, 3261, 2318, 17061, 18, 88, 762, 37432, 819, 11, 1, 888, 14814, 1717, 2321, 11, 88, 88948, 1916, 7063, 819, 447, 3960, 197, 11, 3960, 197, 433, 414, 976, 45, 32958, 4673, 82, 685, 69337, 3570, 164, 18, 97, 11, 244, 800, 8, 52577, 1763, 11, 42363, 37, 8452, 98378, 1090, 55, 17351, 57, 8, 6778, 18, 244, 34, 9814, 15131, 11, 42363, 1061, 54, 274, 778, 726, 8, 13067, 18, 155, 1348, 2376, 172, 211, 56239, 82, 3090, 948, 1387, 7681, 8, 71, 3873, 109, 4984, 1637, 727, 1220, 8, 104, 111, 11, 244, 1939, 68810, 5299, 2703, 27504, 3787, 647, 1730, 8, 165, 248, 11, 42363, 16871, 90, 472, 1507, 82, 4427, 14814, 66, 472, 12834, 82, 278, 472, 974, 11, 54, 1566, 126, 21337, 8, 18, 991, 42363, 244, 500, 50, 98, 1589, 9022, 6175, 13895, 18, 88, 4719, 42046, 40482, 179, 10764, 4152, 185, 11, 42363, 8, 1460, 88, 1, 3229, 586, 179, 129, 120458, 3229, 11, 853, 909, 1239, 6083, 18, 5976, 22650, 11, 42363, 672, 1460, 910, 1057, 9378, 3229, 2697, 341, 54, 428, 77, 182, 114, 8, 796, 1688, 622, 18, 1637, 10470, 3430, 925, 11, 42363, 1460, 1089, 308, 1, 3229, 11, 7827, 1239, 1, 3229, 18, 6870, 7832, 472, 248, 11, 1460, 38270, 325, 14814, 1, 11, 16622, 21794, 26183, 2418, 29971, 8, 2230, 11, 42363, 8, 3053, 10764, 37, 5231, 60, 98, 8, 2632, 2, 4968, 248, 11, 2002, 1373, 389, 6758, 32983, 6778, 313, 21794, 550, 244, 800, 37, 129, 3644, 116, 18, 14249, 11, 7806, 54, 888, 1192, 871, 244, 762, 800, 8, 1338, 472, 475, 18, 1041, 5306, 1, 2364, 11, 7918, 54, 9316, 1763, 8, 3915, 2502, 45790, 8, 7168, 1, 11, 1481, 244, 800, 1177, 129, 188, 5828, 2283, 2283, 6031, 46449, 8, 14249, 129, 11, 13539, 3804, 8, 572, 1588, 244, 8820, 4889, 1336, 55, 21136, 57, 32983, 18, 1566, 800, 11, 42363, 244, 27504, 34700, 8, 188, 367, 7851, 28981, 129, 36479, 6772, 82, 265, 6977, 6772, 11, 877, 14814, 11484, 88, 429, 1220, 8, 1, 116, 308, 1, 11, 793, 1894, 1, 40, 37, 3857, 65155, 3847, 18, 1041, 1070, 4631, 2462, 8, 4011, 32983, 11, 179, 129, 1220, 11, 42363]]]\n",
      "y_list[:1]:[0]\n",
      "x_npa[:1]:[[[   47     1    62 ...   251 10815 11384]\n",
      "  [ 1400   248     6 ...  1481 15748    11]\n",
      "  [11240   650  1964 ... 63425  8475   257]\n",
      "  ...\n",
      "  [  244 24804    55 ...    55 13489    57]\n",
      "  [ 2986 20295   129 ...  6919   188     8]\n",
      "  [21794  2240  3289 ...   576  6529  4554]]]\n",
      "y_npa[:1]:[0]\n",
      "x_npa.shape = (5673, 10, 512)\n",
      "y_npa.shape = (5673,)\n",
      "[[[  1101   1379     55 ...      0      0      0]\n",
      "  [  2964     11    358 ...   1069     11  58143]\n",
      "  [     1   5440  19675 ...   1711   8626     11]\n",
      "  ...\n",
      "  [ 31777 104026  88037 ...   4133    271     54]\n",
      "  [  1016   8523      1 ...   9352   9769   1375]\n",
      "  [  3119  28772    198 ...  28435  28436     11]]\n",
      "\n",
      " [[ 58995      5      2 ...      0      0      0]\n",
      "  [  7174      8      1 ...   6609  25777     18]\n",
      "  [ 12416  19592      1 ...   3008   4125   1552]\n",
      "  ...\n",
      "  [  9253   7395   9688 ...     18    485  29021]\n",
      "  [  2076   1882   5665 ...    112  31473     11]\n",
      "  [ 17675    341   1184 ...  69528      1     11]]\n",
      "\n",
      " [[  4495  11643     11 ...    148     57      8]\n",
      "  [  6241  85120     81 ...   4835   1702   6866]\n",
      "  [  5649     82    238 ...   1357    622   1087]\n",
      "  ...\n",
      "  [ 15704     11      1 ...    148    791      8]\n",
      "  [   241   2011  13888 ...      0      0      0]\n",
      "  [  5602    647  16892 ...      8   5284    472]]]\n",
      "[0 0 1]\n",
      "{0: 1.1130663924761355, 1: 2.27718193977497}\n",
      "Counter({0: 3663, 1: 875})\n",
      "Counter({0: 916, 1: 219})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import collections\n",
    "import sklearn.model_selection\n",
    "import gensim\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from utils import trans_gensim_word2vec2tf_embedding,trans_data2tf_data,trans_tokenize_data2tf_data,trans_multi_input_tokenize_data2npa\n",
    "#from model_multi_textcnn import build_model\n",
    "\n",
    "APP_DIR  = os.path.dirname(os.path.realpath('__file__'))\n",
    "if not os.path.exists(os.path.join(APP_DIR,\"data\")):\n",
    "    os.makedirs(os.path.join(APP_DIR,\"data\"))\n",
    "\n",
    "def split_train_eval_test_dataset(dataset):\n",
    "    \"\"\"区分训练验证测试集\n",
    "    \"\"\"\n",
    "    dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
    "    print(\"总共有数据{}条\".format(dataset_size))\n",
    "    dataset = dataset.shuffle(dataset_size,seed=1)\n",
    "    train_size = int(0.6 * dataset_size)\n",
    "    eval_size = int(0.2 * dataset_size)\n",
    "    test_size = int(0.2 * dataset_size)\n",
    "\n",
    "    train_dataset = dataset.take(train_size)\n",
    "    test_dataset = dataset.skip(train_size)\n",
    "    eval_dataset = test_dataset.skip(eval_size)\n",
    "    test_dataset = test_dataset.take(test_size)\n",
    "    return train_dataset.prefetch(tf.data.experimental.AUTOTUNE), \\\n",
    "        eval_dataset.prefetch(tf.data.experimental.AUTOTUNE), \\\n",
    "        test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "def split_train_eval_test_npa(x_npa,y_npa):\n",
    "    x_train,x_test,y_train,y_test =  sklearn.model_selection.train_test_split(x_npa, y_npa, test_size=0.2, random_state=24)\n",
    "    return x_train,y_train,x_test,y_test\n",
    "\n",
    "def build_model_callback():\n",
    "    callback_path = os.path.join(APP_DIR,\"model_callback\",\"weights.{epoch:02d}-{val_loss:.2f}.hdf5\")\n",
    "    if not os.path.exists(os.path.dirname(callback_path)):\n",
    "        os.makedirs(os.path.dirname(callback_path))\n",
    "\n",
    "    model_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=callback_path,\n",
    "        monitor='val_loss',\n",
    "        verbose=1,\n",
    "        save_best_only=False,\n",
    "        save_weights_only=True,\n",
    "        mode='auto',\n",
    "        save_freq='epoch',\n",
    "    )\n",
    "\n",
    "    tf_board_dir = os.path.join(APP_DIR,\"model_tensorboard\")\n",
    "    if not os.path.exists(os.path.dirname(tf_board_dir)):\n",
    "         os.makedirs(os.path.dirname(tf_board_dir))\n",
    "\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tf_board_dir,histogram_freq=1,update_freq='batch')\n",
    "    return model_callback,tensorboard_callback\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    input_number = 10\n",
    "    #句子的最大长度\n",
    "    sentence_maxlen = 512\n",
    "    #训练次数\n",
    "    epochs = 7\n",
    "    #批大小\n",
    "    batch_size = 64\n",
    "    #学习率\n",
    "    learning_rate = 1e-3\n",
    "    # learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    #     1e-3, decay_steps=100, decay_rate=0.1, staircase=False\n",
    "    # )\n",
    "\n",
    "    #embedding layer是否参加训练\n",
    "    is_embedding_training = False\n",
    "    # is_embedding_training = True\n",
    "    #embedding的dropout比率\n",
    "    #embedding_dropout_rate = 0.35\n",
    "    embedding_dropout_rate = 0.2\n",
    "\n",
    "\n",
    "    #数据文件\n",
    "    #data_csv = os.path.join(APP_DIR,\"data\",\"最终数据集.csv\")\n",
    "    #data_jsonl = os.path.join(APP_DIR,\"data\",\"最终数据集tokenize.jsonl\")\n",
    "    #data_jsonl = \"/mnt1/zhaodachuan/data/predict_user_attribute20200911/raw_data/user_profile/age/最终数据集tokenize.jsonl\"\n",
    "    data_jsonl = r\"/mnt/d/zourui/predict_user_attribute20201214/user_attribute20201231/user_profile/gender/最终数据集tokenize.jsonl\"\n",
    "    #word2vec路径\n",
    "    #word2vector_file_path = os.path.join(APP_DIR,\"data\",\"word2vector.bin\")\n",
    "    word2vector_file_path = r\"/home/zourui/data/dim256/word2vector.bin\"\n",
    "    #模型保存路径\n",
    "    model_path = os.path.join(APP_DIR,\"model_output2\")\n",
    "    ###以上是需要修改的部分\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(model_path)):\n",
    "        os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "    #导入gensim的word2vector\n",
    "    embedding_matrix,word2vector_dict,word2index_dict = trans_gensim_word2vec2tf_embedding(word2vector_file_path)\n",
    "    vocab_size,embedding_dim = embedding_matrix.shape\n",
    "\n",
    "    #划分训练集+验证集，测试集\n",
    "    #x_npa,y_npa,tag2index_dict = trans_data2tf_data(data_csv,sentence_maxlen,word2index_dict)\n",
    "    x_npa,y_npa,tag2index_dict = trans_multi_input_tokenize_data2npa(data_jsonl,sentence_maxlen,word2index_dict)\n",
    "    class_weight_dict = {tag:np.sqrt(len(y_npa)/number) for tag,number in enumerate(np.bincount(y_npa))}\n",
    "    x_train_eval,y_train_eval,x_test,y_test = split_train_eval_test_npa(x_npa,y_npa)\n",
    "    print(x_train_eval[:3])\n",
    "    print(y_train_eval[:3])\n",
    "    print(class_weight_dict)\n",
    "    print(collections.Counter(y_train_eval))\n",
    "    print(collections.Counter(y_test))\n",
    "    tag_size = len(tag2index_dict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gensim\n",
    "import os\n",
    "import LAC\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.utils\n",
    "import time\n",
    "import collections\n",
    "import sklearn.model_selection\n",
    "\n",
    "APP_DIR  = os.path.dirname(os.path.realpath('__file__'))\n",
    "class Number_Transform(object):\n",
    "    \n",
    "    def trans_gensim_word2vec2tf_embedding(self,word2vector_file_path):\n",
    "        \"\"\"把gensim的word2vec结果转化为tf.keras.layers.Embedding需要的结果\n",
    "        \"\"\"\n",
    "        word2vec_model = gensim.models.Word2Vec.load(word2vector_file_path)\n",
    "        #所有的词\n",
    "        word_list = [word for word, word_info in word2vec_model.wv.vocab.items()]\n",
    "        #词到index的映射\n",
    "        word2index_dict = {\"<PADDING>\": 0, \"<UNK>\":1}\n",
    "        #保存特殊词的padding\n",
    "        specical_word_count = len(word2index_dict)\n",
    "        #词到词向量的映射\n",
    "        word2vector_dict = {}\n",
    "        #初始化embeddings_matrix\n",
    "        embeddings_matrix = np.zeros((len(word_list) + specical_word_count, word2vec_model.vector_size))\n",
    "        #初始化unk为-1,1分布\n",
    "        embeddings_matrix[word2index_dict[\"<UNK>\"]] = (1 / np.sqrt(len(word_list) + specical_word_count) * (2 * np.random.rand(word2vec_model.vector_size) - 1))\n",
    "        for i,word in enumerate(word_list):\n",
    "            #从0开始\n",
    "            word_index = i + specical_word_count\n",
    "            word2index_dict[str(word)] = word_index\n",
    "            word2vector_dict[str(word)] = word2vec_model.wv[word] # 词语：词向量\n",
    "            embeddings_matrix[word_index] = word2vec_model.wv[word]  # 词向量矩阵\n",
    "        #写入文件\n",
    "        with open(os.path.join(APP_DIR,\"data\",\"word2index.json\"),\"w\",encoding=\"utf8\") as f:\n",
    "            json.dump(word2index_dict,f,ensure_ascii=False)\n",
    "        return embeddings_matrix,word2vector_dict,word2index_dict\n",
    "\n",
    "\n",
    "    def trans2index(self,word2index_dict,word):\n",
    "        \"\"\"转换\"\"\"\n",
    "        if word in word2index_dict:\n",
    "            return word2index_dict[word]\n",
    "        else:\n",
    "            if \"<UNK>\" in word2index_dict:\n",
    "                return word2index_dict[\"<UNK>\"]\n",
    "            else:\n",
    "                raise ValueError(\"没有这个值，请检查\")\n",
    "\n",
    "    def trans_multi_input_tokenize_data2npa(self,data_file_path,x_max_length,word2index_dict):\n",
    "        \"\"\"把已经分好词的data文件转化为tf.data , 多输入版本\n",
    "        \"\"\"\n",
    "        tag2index_dict = {}\n",
    "        tag_index_count = len(tag2index_dict)\n",
    "        x_list = []\n",
    "        y_list = []\n",
    "        with open(data_file_path) as f:\n",
    "            for line in f:\n",
    "                temp_dict = json.loads(line.strip())\n",
    "                text_tokenize_list = temp_dict[\"all_content_tokenize\"]\n",
    "                tag = temp_dict[\"tag\"].strip()\n",
    "                if not (tag in tag2index_dict):\n",
    "                    tag2index_dict[tag] = tag_index_count\n",
    "                    tag_index_count += 1\n",
    "                x_list.append([[Number_Transform.trans2index(self,word2index_dict,word) for word in word_list] for word_list in text_tokenize_list])\n",
    "                y_list.append(tag2index_dict[tag])\n",
    "        y_npa = np.array(y_list,dtype=np.uint8)\n",
    "\n",
    "      #  print(\"x_list[:1]:{}\".format(x_list[:1]))\n",
    "      #  print(\"y_list[:1]:{}\".format(y_list[:1]))\n",
    "\n",
    "        #写入文件\n",
    "        with open(os.path.join(APP_DIR,\"data/tag2index.json\"),\"w\",encoding=\"utf8\") as f:\n",
    "            json.dump(tag2index_dict,f,ensure_ascii=False)\n",
    "\n",
    "        if not x_max_length:\n",
    "            x_max_length0 = np.max(np.array([len(v) for v in x_list]))\n",
    "            x_max_length = int(np.max(np.percentile(np.array([len(v) for v in x_list]),99.7)))\n",
    "            print(\"数据集中最长的句子长度为:{},设定的最长的句子长度为:{}\".format(x_max_length0,x_max_length))\n",
    "\n",
    "        for i in range(len(x_list)):\n",
    "            x_list[i] = tf.keras.preprocessing.sequence.pad_sequences(x_list[i],maxlen=x_max_length,dtype=np.int32,truncating=\"post\", padding='post',value=0)\n",
    "        x_npa = np.array(x_list,dtype=np.int32)\n",
    "\n",
    "        x_npa,y_npa = sklearn.utils.shuffle(x_npa,y_npa,random_state=0)\n",
    "    #     print(\"x_npa[:1]:{}\".format(x_npa[:1]))\n",
    "    #     print(\"y_npa[:1]:{}\".format(y_npa[:1]))\n",
    "    #     print(\"x_npa.shape = {}\".format(x_npa.shape))\n",
    "    #     print(\"y_npa.shape = {}\".format(y_npa.shape))\n",
    "\n",
    "        return x_npa,y_npa,tag2index_dict\n",
    "\n",
    "    def out_x_y(self,input_number,sentence_maxlen,data_jsonl,word2vector_file_path):\n",
    "\n",
    "        input_number = input_number\n",
    "        #句子的最大长度\n",
    "        sentence_maxlen = sentence_maxlen\n",
    "\n",
    "       # data_jsonl = r\"/mnt/d/zourui/predict_user_attribute20201214/age/raw_data/user_profile/position/最终数据集tokenize8.jsonl\"\n",
    "        #word2vec路径\n",
    "        #word2vector_file_path = os.path.join(APP_DIR,\"data\",\"word2vector.bin\")\n",
    "        word2vector_file_path = word2vector_file_path\n",
    "\n",
    "        #导入gensim的word2vector\n",
    "        embedding_matrix,word2vector_dict,word2index_dict = Number_Transform.trans_gensim_word2vec2tf_embedding(self,word2vector_file_path)\n",
    "        vocab_size,embedding_dim = embedding_matrix.shape\n",
    "\n",
    "        #x_npa,y_npa,tag2index_dict = trans_data2tf_data(data_csv,sentence_maxlen,word2index_dict)\n",
    "        x_npa,y_npa,tag2index_dict = Number_Transform.trans_multi_input_tokenize_data2npa(self,data_jsonl,sentence_maxlen,word2index_dict)\n",
    "        class_weight_dict = {tag:np.sqrt(len(y_npa)/number) for tag,number in enumerate(np.bincount(y_npa))}\n",
    "        tag_size = len(tag2index_dict)\n",
    "        print('转换完毕！')\n",
    "        return x_npa,y_npa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换完毕！\n"
     ]
    }
   ],
   "source": [
    "data_jsonl = \"/mnt/d/zourui/predict_user_attribute20201214/user_attribute20201231/user_profile/gender/最终数据集tokenize.jsonl\"\n",
    "word2vector_file_path = r\"/home/zourui/data/dim256/word2vector.bin\"\n",
    "input_number = 10\n",
    "sentence_maxlen = 512\n",
    "nt = Number_Transform()\n",
    "x_npa,y_npa = nt.out_x_y(input_number,sentence_maxlen,data_jsonl,word2vector_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import LAC\n",
    "from sklearn.feature_selection import RFE\n",
    "import happybase\n",
    "from sklearn.cluster import KMeans \n",
    "import joblib\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class Gender_Model(object):\n",
    "    def train(self,x_npa,y_npa):\n",
    "        y_npa = pd.DataFrame(y_npa)\n",
    "        y_npa.columns = ['gender']\n",
    "        x_npa = x_npa.reshape(len(y_npa),5120)\n",
    "        x_npa = pd.DataFrame(x_npa)\n",
    "        x_npa.columns = [*[\"c{}\".format(v) for v in range(5120)]]\n",
    "        gender_data = pd.merge(y_npa,x_npa,on = y_npa.index)\n",
    "        gender_data = gender_data.drop('key_0',axis = 1)\n",
    "        temp_0 = gender_data.groupby(gender_data.index).filter(lambda x : float(x['gender'])==0)\n",
    "        temp_1 = gender_data.groupby(gender_data.index).filter(lambda x : float(x['gender'])==1)\n",
    "        temp_0 = temp_0.drop('gender',axis = 1)\n",
    "        temp_1 = temp_1.drop('gender',axis = 1)\n",
    "        #聚类\n",
    "        model = KMeans(n_clusters=2)\n",
    "        model.fit(temp_0)\n",
    "        labels = model.predict(temp_0)\n",
    "        labels = pd.DataFrame(labels)\n",
    "        labels.columns = ['b']\n",
    "        temp_00 = pd.merge(labels,temp_0,on = labels.index)\n",
    "        temp_00 = temp_00.drop('key_0',axis=1)\n",
    "        temp_000 = gender_data.groupby(gender_data.index).filter(lambda x : float(x['gender'])==0)\n",
    "        temp_000 = temp_000['gender']\n",
    "        temp_end_0 = pd.merge(temp_000,temp_00,on = temp_00.index)\n",
    "        temp_end_0 = temp_end_0.drop('key_0',axis = 1)\n",
    "        a = dict(collections.Counter(temp_end_0['b']))\n",
    "        b = max(a,key = a.get)\n",
    "        temp_end_0 = temp_end_0.groupby(temp_end_0.index).filter(lambda x:float(x['b'])==b)\n",
    "        model = KMeans(n_clusters=2)\n",
    "        model.fit(temp_1)\n",
    "        labels = model.predict(temp_1)\n",
    "        labels = pd.DataFrame(labels)\n",
    "        labels.columns = ['b']\n",
    "        temp_11 = pd.merge(labels,temp_1,on = labels.index)\n",
    "        temp_11 = temp_11.drop('key_0',axis=1)\n",
    "        temp_111 = gender_data.groupby(gender_data.index).filter(lambda x : float(x['gender'])==1)\n",
    "        temp_111 = temp_111['gender']\n",
    "        temp_end_1 = pd.merge(temp_111,temp_11,on = temp_11.index)\n",
    "        temp_end_1 = temp_end_1.drop('key_0',axis = 1)\n",
    "        a = dict(collections.Counter(temp_end_1['b']))\n",
    "        b = max(a,key = a.get)\n",
    "        temp_end_1 = temp_end_1.groupby(temp_end_1.index).filter(lambda x:float(x['b'])==b)\n",
    "        x_npa1 = pd.concat([temp_end_0, temp_end_1], axis=0, ignore_index=True)\n",
    "        x_npa1 = x_npa1.drop('b',axis = 1)\n",
    "        x_data = x_npa1.drop('gender',axis = 1)\n",
    "        y_data = x_npa1['gender']\n",
    "        ss = StandardScaler()\n",
    "        x_data = ss.fit_transform(x_data)\n",
    "        x_data = pd.DataFrame(x_data)\n",
    "        estimator = SVC(kernel = \"linear\")\n",
    "        selector = RFE(estimator,n_features_to_select = 200,step = 64)\n",
    "        selector = selector.fit(x_data,y_data)\n",
    "        rank = selector.ranking_\n",
    "        rank = pd.DataFrame(rank)\n",
    "        rank.columns = ['rank']\n",
    "        rank.to_csv(gender_rank,index = False)\n",
    "        x_T = x_data.T\n",
    "        rank_data = pd.merge(rank,x_T,on = rank.index)\n",
    "        rank_data = rank_data.drop('key_0',axis = 1)\n",
    "        rank_data_200 = rank_data.groupby(rank_data.index).filter(lambda x : float(x['rank'])==1)\n",
    "        rank_data_200 = rank_data_200.drop('rank',axis = 1)\n",
    "        rank_data_200 = rank_data_200.T\n",
    "        all_data = pd.merge(y_data,rank_data_200,on = y_data.index)\n",
    "        all_data = all_data.drop('key_0',axis = 1)\n",
    "        data_x = all_data.drop('gender',axis = 1)\n",
    "        data_y = all_data['gender']\n",
    "        x_train_data, x_test_data, y_train_data, y_test_data = train_test_split(data_x, data_y, random_state=155)\n",
    "        svm = SVC(C = 1,kernel = 'linear')\n",
    "        svm.fit(x_train_data, y_train_data) \n",
    "        #lr.fit(x_train,y_train)\n",
    "        preds = svm.predict(x_test_data)\n",
    "        print('准确率为%f' %((preds==y_test_data).sum()/float(y_test_data.shape[0])))\n",
    "        return svm\n",
    "    \n",
    "    def save(self,svm):\n",
    "        joblib.dump(svm, gender_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-88a1b5a469d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgender_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/zourui/data/predict_user_attribute20200911/raw_data/gender/model_svm/gender_model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGender_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_npa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_npa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-256b9cbfe725>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_npa, y_npa)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mdata_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gender'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mdata_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gender'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mx_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m155\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0msvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "gender_rank = '/home/zourui/data/predict_user_attribute20200911/raw_data/age/rank/gender_rank.csv'\n",
    "gender_model = '/home/zourui/data/predict_user_attribute20200911/raw_data/gender/model_svm/gender_model'\n",
    "model = Gender_Model()\n",
    "model.train(x_npa,y_npa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "      <th>...</th>\n",
       "      <th>c5110</th>\n",
       "      <th>c5111</th>\n",
       "      <th>c5112</th>\n",
       "      <th>c5113</th>\n",
       "      <th>c5114</th>\n",
       "      <th>c5115</th>\n",
       "      <th>c5116</th>\n",
       "      <th>c5117</th>\n",
       "      <th>c5118</th>\n",
       "      <th>c5119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>3374</td>\n",
       "      <td>401</td>\n",
       "      <td>21794</td>\n",
       "      <td>68756</td>\n",
       "      <td>1032</td>\n",
       "      <td>313</td>\n",
       "      <td>14987</td>\n",
       "      <td>...</td>\n",
       "      <td>18888</td>\n",
       "      <td>1022</td>\n",
       "      <td>244</td>\n",
       "      <td>10013</td>\n",
       "      <td>29704</td>\n",
       "      <td>11829</td>\n",
       "      <td>5064</td>\n",
       "      <td>576</td>\n",
       "      <td>6529</td>\n",
       "      <td>4554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3907</td>\n",
       "      <td>81</td>\n",
       "      <td>5256</td>\n",
       "      <td>61238</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>871</td>\n",
       "      <td>8</td>\n",
       "      <td>8315</td>\n",
       "      <td>...</td>\n",
       "      <td>21145</td>\n",
       "      <td>48850</td>\n",
       "      <td>98</td>\n",
       "      <td>11</td>\n",
       "      <td>1304</td>\n",
       "      <td>126</td>\n",
       "      <td>6</td>\n",
       "      <td>541</td>\n",
       "      <td>2467</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>2357</td>\n",
       "      <td>10781</td>\n",
       "      <td>179</td>\n",
       "      <td>2012</td>\n",
       "      <td>10781</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>6663</td>\n",
       "      <td>14281</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>172</td>\n",
       "      <td>2006</td>\n",
       "      <td>243</td>\n",
       "      <td>12629</td>\n",
       "      <td>15218</td>\n",
       "      <td>82</td>\n",
       "      <td>73020</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1101</td>\n",
       "      <td>1379</td>\n",
       "      <td>55</td>\n",
       "      <td>59914</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>7677</td>\n",
       "      <td>27113</td>\n",
       "      <td>908</td>\n",
       "      <td>18090</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14408</td>\n",
       "      <td>1583</td>\n",
       "      <td>2327</td>\n",
       "      <td>47199</td>\n",
       "      <td>6870</td>\n",
       "      <td>1046</td>\n",
       "      <td>284</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>31305</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>13030</td>\n",
       "      <td>8</td>\n",
       "      <td>86045</td>\n",
       "      <td>2003</td>\n",
       "      <td>54</td>\n",
       "      <td>1340</td>\n",
       "      <td>8</td>\n",
       "      <td>22152</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5668</th>\n",
       "      <td>12279</td>\n",
       "      <td>535</td>\n",
       "      <td>30032</td>\n",
       "      <td>19181</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>13097</td>\n",
       "      <td>4563</td>\n",
       "      <td>27162</td>\n",
       "      <td>14256</td>\n",
       "      <td>...</td>\n",
       "      <td>19659</td>\n",
       "      <td>2732</td>\n",
       "      <td>8</td>\n",
       "      <td>10133</td>\n",
       "      <td>11</td>\n",
       "      <td>8315</td>\n",
       "      <td>98</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>2223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669</th>\n",
       "      <td>34</td>\n",
       "      <td>19863</td>\n",
       "      <td>2970</td>\n",
       "      <td>11</td>\n",
       "      <td>8801</td>\n",
       "      <td>906</td>\n",
       "      <td>362</td>\n",
       "      <td>906</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5213</td>\n",
       "      <td>11</td>\n",
       "      <td>15220</td>\n",
       "      <td>612</td>\n",
       "      <td>5751</td>\n",
       "      <td>781</td>\n",
       "      <td>1011</td>\n",
       "      <td>129</td>\n",
       "      <td>17366</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5670</th>\n",
       "      <td>1</td>\n",
       "      <td>8626</td>\n",
       "      <td>483</td>\n",
       "      <td>109374</td>\n",
       "      <td>495</td>\n",
       "      <td>35053</td>\n",
       "      <td>129</td>\n",
       "      <td>10605</td>\n",
       "      <td>70896</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5671</th>\n",
       "      <td>1</td>\n",
       "      <td>8626</td>\n",
       "      <td>483</td>\n",
       "      <td>109374</td>\n",
       "      <td>495</td>\n",
       "      <td>35053</td>\n",
       "      <td>129</td>\n",
       "      <td>10605</td>\n",
       "      <td>70896</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>11</td>\n",
       "      <td>281</td>\n",
       "      <td>40</td>\n",
       "      <td>37223</td>\n",
       "      <td>2476</td>\n",
       "      <td>55</td>\n",
       "      <td>4166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5672</th>\n",
       "      <td>2964</td>\n",
       "      <td>11</td>\n",
       "      <td>358</td>\n",
       "      <td>6724</td>\n",
       "      <td>464</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>7143</td>\n",
       "      <td>4563</td>\n",
       "      <td>...</td>\n",
       "      <td>319</td>\n",
       "      <td>82</td>\n",
       "      <td>1536</td>\n",
       "      <td>182</td>\n",
       "      <td>8</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "      <td>1460</td>\n",
       "      <td>1589</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5673 rows × 5120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         c0     c1     c2      c3    c4     c5     c6     c7     c8     c9  \\\n",
       "0        47      1     62    3374   401  21794  68756   1032    313  14987   \n",
       "1      3907     81   5256   61238   325      0     55    871      8   8315   \n",
       "2        88   2357  10781     179  2012  10781     11     34   6663  14281   \n",
       "3      1101   1379     55   59914    57      0   7677  27113    908  18090   \n",
       "4     14408   1583   2327   47199  6870   1046    284    325      0  31305   \n",
       "...     ...    ...    ...     ...   ...    ...    ...    ...    ...    ...   \n",
       "5668  12279    535  30032   19181   129      0  13097   4563  27162  14256   \n",
       "5669     34  19863   2970      11  8801    906    362    906    325      0   \n",
       "5670      1   8626    483  109374   495  35053    129  10605  70896     11   \n",
       "5671      1   8626    483  109374   495  35053    129  10605  70896     11   \n",
       "5672   2964     11    358    6724   464      1    129      0   7143   4563   \n",
       "\n",
       "      ...  c5110  c5111  c5112  c5113  c5114  c5115  c5116  c5117  c5118  \\\n",
       "0     ...  18888   1022    244  10013  29704  11829   5064    576   6529   \n",
       "1     ...  21145  48850     98     11   1304    126      6    541   2467   \n",
       "2     ...     34      8    172   2006    243  12629  15218     82  73020   \n",
       "3     ...      0      0      0      0      0      0      0      0      0   \n",
       "4     ...     11  13030      8  86045   2003     54   1340      8  22152   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "5668  ...  19659   2732      8  10133     11   8315     98     54      1   \n",
       "5669  ...   5213     11  15220    612   5751    781   1011    129  17366   \n",
       "5670  ...      0      0      0      0      0      0      0      0      0   \n",
       "5671  ...    112      1     98     11    281     40  37223   2476     55   \n",
       "5672  ...    319     82   1536    182      8    103     11   1460   1589   \n",
       "\n",
       "      c5119  \n",
       "0      4554  \n",
       "1       567  \n",
       "2       514  \n",
       "3         0  \n",
       "4        11  \n",
       "...     ...  \n",
       "5668   2223  \n",
       "5669     18  \n",
       "5670      0  \n",
       "5671   4166  \n",
       "5672    475  \n",
       "\n",
       "[5673 rows x 5120 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_npa = pd.DataFrame(y_npa)\n",
    "y_npa.columns = ['gender']\n",
    "x_npa = x_npa.reshape(len(y_npa),5120)\n",
    "x_npa = pd.DataFrame(x_npa)\n",
    "x_npa.columns = [*[\"c{}\".format(v) for v in range(5120)]]\n",
    "x_npa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>...</th>\n",
       "      <th>c5110</th>\n",
       "      <th>c5111</th>\n",
       "      <th>c5112</th>\n",
       "      <th>c5113</th>\n",
       "      <th>c5114</th>\n",
       "      <th>c5115</th>\n",
       "      <th>c5116</th>\n",
       "      <th>c5117</th>\n",
       "      <th>c5118</th>\n",
       "      <th>c5119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>3374</td>\n",
       "      <td>401</td>\n",
       "      <td>21794</td>\n",
       "      <td>68756</td>\n",
       "      <td>1032</td>\n",
       "      <td>313</td>\n",
       "      <td>...</td>\n",
       "      <td>18888</td>\n",
       "      <td>1022</td>\n",
       "      <td>244</td>\n",
       "      <td>10013</td>\n",
       "      <td>29704</td>\n",
       "      <td>11829</td>\n",
       "      <td>5064</td>\n",
       "      <td>576</td>\n",
       "      <td>6529</td>\n",
       "      <td>4554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3907</td>\n",
       "      <td>81</td>\n",
       "      <td>5256</td>\n",
       "      <td>61238</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>871</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>21145</td>\n",
       "      <td>48850</td>\n",
       "      <td>98</td>\n",
       "      <td>11</td>\n",
       "      <td>1304</td>\n",
       "      <td>126</td>\n",
       "      <td>6</td>\n",
       "      <td>541</td>\n",
       "      <td>2467</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>2357</td>\n",
       "      <td>10781</td>\n",
       "      <td>179</td>\n",
       "      <td>2012</td>\n",
       "      <td>10781</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>6663</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>172</td>\n",
       "      <td>2006</td>\n",
       "      <td>243</td>\n",
       "      <td>12629</td>\n",
       "      <td>15218</td>\n",
       "      <td>82</td>\n",
       "      <td>73020</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1101</td>\n",
       "      <td>1379</td>\n",
       "      <td>55</td>\n",
       "      <td>59914</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>7677</td>\n",
       "      <td>27113</td>\n",
       "      <td>908</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14408</td>\n",
       "      <td>1583</td>\n",
       "      <td>2327</td>\n",
       "      <td>47199</td>\n",
       "      <td>6870</td>\n",
       "      <td>1046</td>\n",
       "      <td>284</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>13030</td>\n",
       "      <td>8</td>\n",
       "      <td>86045</td>\n",
       "      <td>2003</td>\n",
       "      <td>54</td>\n",
       "      <td>1340</td>\n",
       "      <td>8</td>\n",
       "      <td>22152</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5668</th>\n",
       "      <td>1</td>\n",
       "      <td>12279</td>\n",
       "      <td>535</td>\n",
       "      <td>30032</td>\n",
       "      <td>19181</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>13097</td>\n",
       "      <td>4563</td>\n",
       "      <td>27162</td>\n",
       "      <td>...</td>\n",
       "      <td>19659</td>\n",
       "      <td>2732</td>\n",
       "      <td>8</td>\n",
       "      <td>10133</td>\n",
       "      <td>11</td>\n",
       "      <td>8315</td>\n",
       "      <td>98</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>2223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>19863</td>\n",
       "      <td>2970</td>\n",
       "      <td>11</td>\n",
       "      <td>8801</td>\n",
       "      <td>906</td>\n",
       "      <td>362</td>\n",
       "      <td>906</td>\n",
       "      <td>325</td>\n",
       "      <td>...</td>\n",
       "      <td>5213</td>\n",
       "      <td>11</td>\n",
       "      <td>15220</td>\n",
       "      <td>612</td>\n",
       "      <td>5751</td>\n",
       "      <td>781</td>\n",
       "      <td>1011</td>\n",
       "      <td>129</td>\n",
       "      <td>17366</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5670</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8626</td>\n",
       "      <td>483</td>\n",
       "      <td>109374</td>\n",
       "      <td>495</td>\n",
       "      <td>35053</td>\n",
       "      <td>129</td>\n",
       "      <td>10605</td>\n",
       "      <td>70896</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5671</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8626</td>\n",
       "      <td>483</td>\n",
       "      <td>109374</td>\n",
       "      <td>495</td>\n",
       "      <td>35053</td>\n",
       "      <td>129</td>\n",
       "      <td>10605</td>\n",
       "      <td>70896</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>11</td>\n",
       "      <td>281</td>\n",
       "      <td>40</td>\n",
       "      <td>37223</td>\n",
       "      <td>2476</td>\n",
       "      <td>55</td>\n",
       "      <td>4166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5672</th>\n",
       "      <td>0</td>\n",
       "      <td>2964</td>\n",
       "      <td>11</td>\n",
       "      <td>358</td>\n",
       "      <td>6724</td>\n",
       "      <td>464</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>7143</td>\n",
       "      <td>...</td>\n",
       "      <td>319</td>\n",
       "      <td>82</td>\n",
       "      <td>1536</td>\n",
       "      <td>182</td>\n",
       "      <td>8</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "      <td>1460</td>\n",
       "      <td>1589</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5673 rows × 5121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender     c0     c1     c2      c3    c4     c5     c6     c7     c8  \\\n",
       "0          0     47      1     62    3374   401  21794  68756   1032    313   \n",
       "1          1   3907     81   5256   61238   325      0     55    871      8   \n",
       "2          0     88   2357  10781     179  2012  10781     11     34   6663   \n",
       "3          1   1101   1379     55   59914    57      0   7677  27113    908   \n",
       "4          0  14408   1583   2327   47199  6870   1046    284    325      0   \n",
       "...      ...    ...    ...    ...     ...   ...    ...    ...    ...    ...   \n",
       "5668       1  12279    535  30032   19181   129      0  13097   4563  27162   \n",
       "5669       1     34  19863   2970      11  8801    906    362    906    325   \n",
       "5670       0      1   8626    483  109374   495  35053    129  10605  70896   \n",
       "5671       0      1   8626    483  109374   495  35053    129  10605  70896   \n",
       "5672       0   2964     11    358    6724   464      1    129      0   7143   \n",
       "\n",
       "      ...  c5110  c5111  c5112  c5113  c5114  c5115  c5116  c5117  c5118  \\\n",
       "0     ...  18888   1022    244  10013  29704  11829   5064    576   6529   \n",
       "1     ...  21145  48850     98     11   1304    126      6    541   2467   \n",
       "2     ...     34      8    172   2006    243  12629  15218     82  73020   \n",
       "3     ...      0      0      0      0      0      0      0      0      0   \n",
       "4     ...     11  13030      8  86045   2003     54   1340      8  22152   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "5668  ...  19659   2732      8  10133     11   8315     98     54      1   \n",
       "5669  ...   5213     11  15220    612   5751    781   1011    129  17366   \n",
       "5670  ...      0      0      0      0      0      0      0      0      0   \n",
       "5671  ...    112      1     98     11    281     40  37223   2476     55   \n",
       "5672  ...    319     82   1536    182      8    103     11   1460   1589   \n",
       "\n",
       "      c5119  \n",
       "0      4554  \n",
       "1       567  \n",
       "2       514  \n",
       "3         0  \n",
       "4        11  \n",
       "...     ...  \n",
       "5668   2223  \n",
       "5669     18  \n",
       "5670      0  \n",
       "5671   4166  \n",
       "5672    475  \n",
       "\n",
       "[5673 rows x 5121 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_data = pd.merge(y_npa,x_npa,on = y_npa.index)\n",
    "gender_data = gender_data.drop('key_0',axis = 1)\n",
    "gender_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_0 = gender_data.groupby(gender_data.index).filter(lambda x : float(x['gender'])==0)\n",
    "temp_1 = gender_data.groupby(gender_data.index).filter(lambda x : float(x['gender'])==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_0 = temp_0.drop('gender',axis = 1)\n",
    "temp_1 = temp_1.drop('gender',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>...</th>\n",
       "      <th>c5110</th>\n",
       "      <th>c5111</th>\n",
       "      <th>c5112</th>\n",
       "      <th>c5113</th>\n",
       "      <th>c5114</th>\n",
       "      <th>c5115</th>\n",
       "      <th>c5116</th>\n",
       "      <th>c5117</th>\n",
       "      <th>c5118</th>\n",
       "      <th>c5119</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3959</td>\n",
       "      <td>3959</td>\n",
       "      <td>3959</td>\n",
       "      <td>3959</td>\n",
       "      <td>3959</td>\n",
       "      <td>3959</td>\n",
       "      <td>3959</td>\n",
       "      <td>3959</td>\n",
       "      <td>3959</td>\n",
       "      <td>3959</td>\n",
       "      <td>...</td>\n",
       "      <td>3959</td>\n",
       "      <td>3959</td>\n",
       "      <td>3959</td>\n",
       "      <td>3959</td>\n",
       "      <td>3959</td>\n",
       "      <td>3959</td>\n",
       "      <td>3959</td>\n",
       "      <td>3959</td>\n",
       "      <td>3959</td>\n",
       "      <td>3959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>...</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 5121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender    c0    c1    c2    c3    c4    c5    c6    c7    c8  ...  c5110  \\\n",
       "b                                                                ...          \n",
       "0    3959  3959  3959  3959  3959  3959  3959  3959  3959  3959  ...   3959   \n",
       "1     620   620   620   620   620   620   620   620   620   620  ...    620   \n",
       "\n",
       "   c5111  c5112  c5113  c5114  c5115  c5116  c5117  c5118  c5119  \n",
       "b                                                                 \n",
       "0   3959   3959   3959   3959   3959   3959   3959   3959   3959  \n",
       "1    620    620    620    620    620    620    620    620    620  \n",
       "\n",
       "[2 rows x 5121 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>b</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>...</th>\n",
       "      <th>c5110</th>\n",
       "      <th>c5111</th>\n",
       "      <th>c5112</th>\n",
       "      <th>c5113</th>\n",
       "      <th>c5114</th>\n",
       "      <th>c5115</th>\n",
       "      <th>c5116</th>\n",
       "      <th>c5117</th>\n",
       "      <th>c5118</th>\n",
       "      <th>c5119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>3374</td>\n",
       "      <td>401</td>\n",
       "      <td>21794</td>\n",
       "      <td>68756</td>\n",
       "      <td>1032</td>\n",
       "      <td>...</td>\n",
       "      <td>18888</td>\n",
       "      <td>1022</td>\n",
       "      <td>244</td>\n",
       "      <td>10013</td>\n",
       "      <td>29704</td>\n",
       "      <td>11829</td>\n",
       "      <td>5064</td>\n",
       "      <td>576</td>\n",
       "      <td>6529</td>\n",
       "      <td>4554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>2357</td>\n",
       "      <td>10781</td>\n",
       "      <td>179</td>\n",
       "      <td>2012</td>\n",
       "      <td>10781</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>172</td>\n",
       "      <td>2006</td>\n",
       "      <td>243</td>\n",
       "      <td>12629</td>\n",
       "      <td>15218</td>\n",
       "      <td>82</td>\n",
       "      <td>73020</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14408</td>\n",
       "      <td>1583</td>\n",
       "      <td>2327</td>\n",
       "      <td>47199</td>\n",
       "      <td>6870</td>\n",
       "      <td>1046</td>\n",
       "      <td>284</td>\n",
       "      <td>325</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>13030</td>\n",
       "      <td>8</td>\n",
       "      <td>86045</td>\n",
       "      <td>2003</td>\n",
       "      <td>54</td>\n",
       "      <td>1340</td>\n",
       "      <td>8</td>\n",
       "      <td>22152</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40009</td>\n",
       "      <td>68250</td>\n",
       "      <td>11</td>\n",
       "      <td>13861</td>\n",
       "      <td>17849</td>\n",
       "      <td>2877</td>\n",
       "      <td>129</td>\n",
       "      <td>274</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>103128</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>38888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5689</td>\n",
       "      <td>11033</td>\n",
       "      <td>11</td>\n",
       "      <td>21659</td>\n",
       "      <td>112</td>\n",
       "      <td>44192</td>\n",
       "      <td>0</td>\n",
       "      <td>4719</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>4433</td>\n",
       "      <td>54150</td>\n",
       "      <td>650</td>\n",
       "      <td>11</td>\n",
       "      <td>18260</td>\n",
       "      <td>235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4574</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>2357</td>\n",
       "      <td>10781</td>\n",
       "      <td>179</td>\n",
       "      <td>2012</td>\n",
       "      <td>10781</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>2377</td>\n",
       "      <td>1</td>\n",
       "      <td>36754</td>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "      <td>5476</td>\n",
       "      <td>57</td>\n",
       "      <td>1326</td>\n",
       "      <td>11</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4575</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51742</td>\n",
       "      <td>11</td>\n",
       "      <td>888</td>\n",
       "      <td>19350</td>\n",
       "      <td>1148</td>\n",
       "      <td>2842</td>\n",
       "      <td>11</td>\n",
       "      <td>15747</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2611</td>\n",
       "      <td>8509</td>\n",
       "      <td>1999</td>\n",
       "      <td>700</td>\n",
       "      <td>211</td>\n",
       "      <td>129</td>\n",
       "      <td>4983</td>\n",
       "      <td>11</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4576</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8626</td>\n",
       "      <td>483</td>\n",
       "      <td>109374</td>\n",
       "      <td>495</td>\n",
       "      <td>35053</td>\n",
       "      <td>129</td>\n",
       "      <td>10605</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4577</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8626</td>\n",
       "      <td>483</td>\n",
       "      <td>109374</td>\n",
       "      <td>495</td>\n",
       "      <td>35053</td>\n",
       "      <td>129</td>\n",
       "      <td>10605</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>11</td>\n",
       "      <td>281</td>\n",
       "      <td>40</td>\n",
       "      <td>37223</td>\n",
       "      <td>2476</td>\n",
       "      <td>55</td>\n",
       "      <td>4166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2964</td>\n",
       "      <td>11</td>\n",
       "      <td>358</td>\n",
       "      <td>6724</td>\n",
       "      <td>464</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>319</td>\n",
       "      <td>82</td>\n",
       "      <td>1536</td>\n",
       "      <td>182</td>\n",
       "      <td>8</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "      <td>1460</td>\n",
       "      <td>1589</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3959 rows × 5122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  b     c0     c1     c2      c3     c4     c5     c6     c7  ...  \\\n",
       "0          0  0     47      1     62    3374    401  21794  68756   1032  ...   \n",
       "1          0  0     88   2357  10781     179   2012  10781     11     34  ...   \n",
       "2          0  0  14408   1583   2327   47199   6870   1046    284    325  ...   \n",
       "3          0  0  40009  68250     11   13861  17849   2877    129    274  ...   \n",
       "4          0  0   5689  11033     11   21659    112  44192      0   4719  ...   \n",
       "...      ... ..    ...    ...    ...     ...    ...    ...    ...    ...  ...   \n",
       "4574       0  0     88   2357  10781     179   2012  10781     11     34  ...   \n",
       "4575       0  0  51742     11    888   19350   1148   2842     11  15747  ...   \n",
       "4576       0  0      1   8626    483  109374    495  35053    129  10605  ...   \n",
       "4577       0  0      1   8626    483  109374    495  35053    129  10605  ...   \n",
       "4578       0  0   2964     11    358    6724    464      1    129      0  ...   \n",
       "\n",
       "      c5110  c5111  c5112  c5113   c5114  c5115  c5116  c5117  c5118  c5119  \n",
       "0     18888   1022    244  10013   29704  11829   5064    576   6529   4554  \n",
       "1        34      8    172   2006     243  12629  15218     82  73020    514  \n",
       "2        11  13030      8  86045    2003     54   1340      8  22152     11  \n",
       "3         1     82      1     82  103128     82      1     82      1  38888  \n",
       "4        54   4433  54150    650      11  18260    235      1      1   3332  \n",
       "...     ...    ...    ...    ...     ...    ...    ...    ...    ...    ...  \n",
       "4574   2377      1  36754      8      55   5476     57   1326     11    127  \n",
       "4575      8   2611   8509   1999     700    211    129   4983     11     84  \n",
       "4576      0      0      0      0       0      0      0      0      0      0  \n",
       "4577    112      1     98     11     281     40  37223   2476     55   4166  \n",
       "4578    319     82   1536    182       8    103     11   1460   1589    475  \n",
       "\n",
       "[3959 rows x 5122 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#聚类\n",
    "model = KMeans(n_clusters=2)\n",
    "model.fit(temp_0)\n",
    "labels = model.predict(temp_0)\n",
    "labels = pd.DataFrame(labels)\n",
    "labels.columns = ['b']\n",
    "temp_00 = pd.merge(labels,temp_0,on = labels.index)\n",
    "temp_00 = temp_00.drop('key_0',axis=1)\n",
    "temp_000 = gender_data.groupby(gender_data.index).filter(lambda x : float(x['gender'])==0)\n",
    "temp_000 = temp_000['gender']\n",
    "temp_end_0 = pd.merge(temp_000,temp_00,on = temp_00.index)\n",
    "temp_end_0 = temp_end_0.drop('key_0',axis = 1)\n",
    "a = dict(collections.Counter(temp_end_0['b']))\n",
    "b = max(a,key = a.get)\n",
    "temp_end_0 = temp_end_0.groupby(temp_end_0.index).filter(lambda x:float(x['b'])==b)\n",
    "temp_end_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>b</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>...</th>\n",
       "      <th>c5110</th>\n",
       "      <th>c5111</th>\n",
       "      <th>c5112</th>\n",
       "      <th>c5113</th>\n",
       "      <th>c5114</th>\n",
       "      <th>c5115</th>\n",
       "      <th>c5116</th>\n",
       "      <th>c5117</th>\n",
       "      <th>c5118</th>\n",
       "      <th>c5119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3907</td>\n",
       "      <td>81</td>\n",
       "      <td>5256</td>\n",
       "      <td>61238</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>871</td>\n",
       "      <td>...</td>\n",
       "      <td>21145</td>\n",
       "      <td>48850</td>\n",
       "      <td>98</td>\n",
       "      <td>11</td>\n",
       "      <td>1304</td>\n",
       "      <td>126</td>\n",
       "      <td>6</td>\n",
       "      <td>541</td>\n",
       "      <td>2467</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1101</td>\n",
       "      <td>1379</td>\n",
       "      <td>55</td>\n",
       "      <td>59914</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>7677</td>\n",
       "      <td>27113</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29940</td>\n",
       "      <td>11</td>\n",
       "      <td>15190</td>\n",
       "      <td>12726</td>\n",
       "      <td>378</td>\n",
       "      <td>8381</td>\n",
       "      <td>8</td>\n",
       "      <td>14336</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>1322</td>\n",
       "      <td>44166</td>\n",
       "      <td>45</td>\n",
       "      <td>3973</td>\n",
       "      <td>11</td>\n",
       "      <td>18839</td>\n",
       "      <td>42401</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12041</td>\n",
       "      <td>8</td>\n",
       "      <td>5658</td>\n",
       "      <td>1968</td>\n",
       "      <td>0</td>\n",
       "      <td>1041</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>1674</td>\n",
       "      <td>17142</td>\n",
       "      <td>3413</td>\n",
       "      <td>67</td>\n",
       "      <td>16601</td>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31777</td>\n",
       "      <td>13887</td>\n",
       "      <td>16212</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>9459</td>\n",
       "      <td>43435</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>24509</td>\n",
       "      <td>84</td>\n",
       "      <td>1239</td>\n",
       "      <td>4839</td>\n",
       "      <td>9261</td>\n",
       "      <td>11</td>\n",
       "      <td>87122</td>\n",
       "      <td>8</td>\n",
       "      <td>272</td>\n",
       "      <td>7795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35478</td>\n",
       "      <td>46261</td>\n",
       "      <td>34142</td>\n",
       "      <td>12756</td>\n",
       "      <td>11</td>\n",
       "      <td>127</td>\n",
       "      <td>61256</td>\n",
       "      <td>362</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>495</td>\n",
       "      <td>67</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "      <td>507</td>\n",
       "      <td>146</td>\n",
       "      <td>11</td>\n",
       "      <td>11367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6938</td>\n",
       "      <td>2309</td>\n",
       "      <td>11</td>\n",
       "      <td>244</td>\n",
       "      <td>34</td>\n",
       "      <td>2415</td>\n",
       "      <td>9399</td>\n",
       "      <td>2327</td>\n",
       "      <td>...</td>\n",
       "      <td>25677</td>\n",
       "      <td>2177</td>\n",
       "      <td>892</td>\n",
       "      <td>5375</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>13543</td>\n",
       "      <td>389</td>\n",
       "      <td>19933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1620</td>\n",
       "      <td>11</td>\n",
       "      <td>26303</td>\n",
       "      <td>2205</td>\n",
       "      <td>54</td>\n",
       "      <td>44662</td>\n",
       "      <td>34846</td>\n",
       "      <td>...</td>\n",
       "      <td>1630</td>\n",
       "      <td>119</td>\n",
       "      <td>112</td>\n",
       "      <td>8909</td>\n",
       "      <td>112</td>\n",
       "      <td>8</td>\n",
       "      <td>38</td>\n",
       "      <td>12621</td>\n",
       "      <td>128</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12279</td>\n",
       "      <td>535</td>\n",
       "      <td>30032</td>\n",
       "      <td>19181</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>13097</td>\n",
       "      <td>4563</td>\n",
       "      <td>...</td>\n",
       "      <td>19659</td>\n",
       "      <td>2732</td>\n",
       "      <td>8</td>\n",
       "      <td>10133</td>\n",
       "      <td>11</td>\n",
       "      <td>8315</td>\n",
       "      <td>98</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>2223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>19863</td>\n",
       "      <td>2970</td>\n",
       "      <td>11</td>\n",
       "      <td>8801</td>\n",
       "      <td>906</td>\n",
       "      <td>362</td>\n",
       "      <td>906</td>\n",
       "      <td>...</td>\n",
       "      <td>5213</td>\n",
       "      <td>11</td>\n",
       "      <td>15220</td>\n",
       "      <td>612</td>\n",
       "      <td>5751</td>\n",
       "      <td>781</td>\n",
       "      <td>1011</td>\n",
       "      <td>129</td>\n",
       "      <td>17366</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1051 rows × 5122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  b     c0     c1     c2     c3    c4    c5     c6     c7  ...  \\\n",
       "0          1  0   3907     81   5256  61238   325     0     55    871  ...   \n",
       "1          1  0   1101   1379     55  59914    57     0   7677  27113  ...   \n",
       "2          1  0  29940     11  15190  12726   378  8381      8  14336  ...   \n",
       "3          1  0      1      2  12041      8  5658  1968      0   1041  ...   \n",
       "4          1  0  31777  13887  16212      1    11  9459  43435      6  ...   \n",
       "...      ... ..    ...    ...    ...    ...   ...   ...    ...    ...  ...   \n",
       "1089       1  0  35478  46261  34142  12756    11   127  61256    362  ...   \n",
       "1090       1  0   6938   2309     11    244    34  2415   9399   2327  ...   \n",
       "1091       1  0      1   1620     11  26303  2205    54  44662  34846  ...   \n",
       "1092       1  0  12279    535  30032  19181   129     0  13097   4563  ...   \n",
       "1093       1  0     34  19863   2970     11  8801   906    362    906  ...   \n",
       "\n",
       "      c5110  c5111  c5112  c5113  c5114  c5115  c5116  c5117  c5118  c5119  \n",
       "0     21145  48850     98     11   1304    126      6    541   2467    567  \n",
       "1         0      0      0      0      0      0      0      0      0      0  \n",
       "2        40   1322  44166     45   3973     11  18839  42401     18      1  \n",
       "3       109      1   1674  17142   3413     67  16601      8     55      1  \n",
       "4     24509     84   1239   4839   9261     11  87122      8    272   7795  \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "1089      1    495     67      8      1    244    507    146     11  11367  \n",
       "1090  25677   2177    892   5375      1     11     40  13543    389  19933  \n",
       "1091   1630    119    112   8909    112      8     38  12621    128    877  \n",
       "1092  19659   2732      8  10133     11   8315     98     54      1   2223  \n",
       "1093   5213     11  15220    612   5751    781   1011    129  17366     18  \n",
       "\n",
       "[1051 rows x 5122 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KMeans(n_clusters=2)\n",
    "model.fit(temp_1)\n",
    "labels = model.predict(temp_1)\n",
    "labels = pd.DataFrame(labels)\n",
    "labels.columns = ['b']\n",
    "temp_11 = pd.merge(labels,temp_1,on = labels.index)\n",
    "temp_11 = temp_11.drop('key_0',axis=1)\n",
    "temp_111 = gender_data.groupby(gender_data.index).filter(lambda x : float(x['gender'])==1)\n",
    "temp_111 = temp_111['gender']\n",
    "temp_end_1 = pd.merge(temp_111,temp_11,on = temp_11.index)\n",
    "temp_end_1 = temp_end_1.drop('key_0',axis = 1)\n",
    "a = dict(collections.Counter(temp_end_1['b']))\n",
    "b = max(a,key = a.get)\n",
    "temp_end_1 = temp_end_1.groupby(temp_end_1.index).filter(lambda x:float(x['b'])==b)\n",
    "temp_end_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>...</th>\n",
       "      <th>c5110</th>\n",
       "      <th>c5111</th>\n",
       "      <th>c5112</th>\n",
       "      <th>c5113</th>\n",
       "      <th>c5114</th>\n",
       "      <th>c5115</th>\n",
       "      <th>c5116</th>\n",
       "      <th>c5117</th>\n",
       "      <th>c5118</th>\n",
       "      <th>c5119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>3374</td>\n",
       "      <td>401</td>\n",
       "      <td>21794</td>\n",
       "      <td>68756</td>\n",
       "      <td>1032</td>\n",
       "      <td>313</td>\n",
       "      <td>...</td>\n",
       "      <td>18888</td>\n",
       "      <td>1022</td>\n",
       "      <td>244</td>\n",
       "      <td>10013</td>\n",
       "      <td>29704</td>\n",
       "      <td>11829</td>\n",
       "      <td>5064</td>\n",
       "      <td>576</td>\n",
       "      <td>6529</td>\n",
       "      <td>4554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>2357</td>\n",
       "      <td>10781</td>\n",
       "      <td>179</td>\n",
       "      <td>2012</td>\n",
       "      <td>10781</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>6663</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>172</td>\n",
       "      <td>2006</td>\n",
       "      <td>243</td>\n",
       "      <td>12629</td>\n",
       "      <td>15218</td>\n",
       "      <td>82</td>\n",
       "      <td>73020</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>14408</td>\n",
       "      <td>1583</td>\n",
       "      <td>2327</td>\n",
       "      <td>47199</td>\n",
       "      <td>6870</td>\n",
       "      <td>1046</td>\n",
       "      <td>284</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>13030</td>\n",
       "      <td>8</td>\n",
       "      <td>86045</td>\n",
       "      <td>2003</td>\n",
       "      <td>54</td>\n",
       "      <td>1340</td>\n",
       "      <td>8</td>\n",
       "      <td>22152</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40009</td>\n",
       "      <td>68250</td>\n",
       "      <td>11</td>\n",
       "      <td>13861</td>\n",
       "      <td>17849</td>\n",
       "      <td>2877</td>\n",
       "      <td>129</td>\n",
       "      <td>274</td>\n",
       "      <td>25742</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>103128</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>38888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5689</td>\n",
       "      <td>11033</td>\n",
       "      <td>11</td>\n",
       "      <td>21659</td>\n",
       "      <td>112</td>\n",
       "      <td>44192</td>\n",
       "      <td>0</td>\n",
       "      <td>4719</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>4433</td>\n",
       "      <td>54150</td>\n",
       "      <td>650</td>\n",
       "      <td>11</td>\n",
       "      <td>18260</td>\n",
       "      <td>235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>1</td>\n",
       "      <td>35478</td>\n",
       "      <td>46261</td>\n",
       "      <td>34142</td>\n",
       "      <td>12756</td>\n",
       "      <td>11</td>\n",
       "      <td>127</td>\n",
       "      <td>61256</td>\n",
       "      <td>362</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>495</td>\n",
       "      <td>67</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "      <td>507</td>\n",
       "      <td>146</td>\n",
       "      <td>11</td>\n",
       "      <td>11367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>1</td>\n",
       "      <td>6938</td>\n",
       "      <td>2309</td>\n",
       "      <td>11</td>\n",
       "      <td>244</td>\n",
       "      <td>34</td>\n",
       "      <td>2415</td>\n",
       "      <td>9399</td>\n",
       "      <td>2327</td>\n",
       "      <td>2224</td>\n",
       "      <td>...</td>\n",
       "      <td>25677</td>\n",
       "      <td>2177</td>\n",
       "      <td>892</td>\n",
       "      <td>5375</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>13543</td>\n",
       "      <td>389</td>\n",
       "      <td>19933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1620</td>\n",
       "      <td>11</td>\n",
       "      <td>26303</td>\n",
       "      <td>2205</td>\n",
       "      <td>54</td>\n",
       "      <td>44662</td>\n",
       "      <td>34846</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1630</td>\n",
       "      <td>119</td>\n",
       "      <td>112</td>\n",
       "      <td>8909</td>\n",
       "      <td>112</td>\n",
       "      <td>8</td>\n",
       "      <td>38</td>\n",
       "      <td>12621</td>\n",
       "      <td>128</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>1</td>\n",
       "      <td>12279</td>\n",
       "      <td>535</td>\n",
       "      <td>30032</td>\n",
       "      <td>19181</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>13097</td>\n",
       "      <td>4563</td>\n",
       "      <td>27162</td>\n",
       "      <td>...</td>\n",
       "      <td>19659</td>\n",
       "      <td>2732</td>\n",
       "      <td>8</td>\n",
       "      <td>10133</td>\n",
       "      <td>11</td>\n",
       "      <td>8315</td>\n",
       "      <td>98</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>2223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>19863</td>\n",
       "      <td>2970</td>\n",
       "      <td>11</td>\n",
       "      <td>8801</td>\n",
       "      <td>906</td>\n",
       "      <td>362</td>\n",
       "      <td>906</td>\n",
       "      <td>325</td>\n",
       "      <td>...</td>\n",
       "      <td>5213</td>\n",
       "      <td>11</td>\n",
       "      <td>15220</td>\n",
       "      <td>612</td>\n",
       "      <td>5751</td>\n",
       "      <td>781</td>\n",
       "      <td>1011</td>\n",
       "      <td>129</td>\n",
       "      <td>17366</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5010 rows × 5121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender     c0     c1     c2     c3     c4     c5     c6     c7     c8  \\\n",
       "0          0     47      1     62   3374    401  21794  68756   1032    313   \n",
       "1          0     88   2357  10781    179   2012  10781     11     34   6663   \n",
       "2          0  14408   1583   2327  47199   6870   1046    284    325      0   \n",
       "3          0  40009  68250     11  13861  17849   2877    129    274  25742   \n",
       "4          0   5689  11033     11  21659    112  44192      0   4719    112   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "5005       1  35478  46261  34142  12756     11    127  61256    362     98   \n",
       "5006       1   6938   2309     11    244     34   2415   9399   2327   2224   \n",
       "5007       1      1   1620     11  26303   2205     54  44662  34846      0   \n",
       "5008       1  12279    535  30032  19181    129      0  13097   4563  27162   \n",
       "5009       1     34  19863   2970     11   8801    906    362    906    325   \n",
       "\n",
       "      ...  c5110  c5111  c5112  c5113   c5114  c5115  c5116  c5117  c5118  \\\n",
       "0     ...  18888   1022    244  10013   29704  11829   5064    576   6529   \n",
       "1     ...     34      8    172   2006     243  12629  15218     82  73020   \n",
       "2     ...     11  13030      8  86045    2003     54   1340      8  22152   \n",
       "3     ...      1     82      1     82  103128     82      1     82      1   \n",
       "4     ...     54   4433  54150    650      11  18260    235      1      1   \n",
       "...   ...    ...    ...    ...    ...     ...    ...    ...    ...    ...   \n",
       "5005  ...      1    495     67      8       1    244    507    146     11   \n",
       "5006  ...  25677   2177    892   5375       1     11     40  13543    389   \n",
       "5007  ...   1630    119    112   8909     112      8     38  12621    128   \n",
       "5008  ...  19659   2732      8  10133      11   8315     98     54      1   \n",
       "5009  ...   5213     11  15220    612    5751    781   1011    129  17366   \n",
       "\n",
       "      c5119  \n",
       "0      4554  \n",
       "1       514  \n",
       "2        11  \n",
       "3     38888  \n",
       "4      3332  \n",
       "...     ...  \n",
       "5005  11367  \n",
       "5006  19933  \n",
       "5007    877  \n",
       "5008   2223  \n",
       "5009     18  \n",
       "\n",
       "[5010 rows x 5121 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_npa1 = pd.concat([temp_end_0, temp_end_1], axis=0, ignore_index=True)\n",
    "x_npa1 = x_npa1.drop('b',axis = 1)\n",
    "x_npa1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_npa1.drop('gender',axis = 1)\n",
    "y_data = x_npa1['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5110</th>\n",
       "      <th>5111</th>\n",
       "      <th>5112</th>\n",
       "      <th>5113</th>\n",
       "      <th>5114</th>\n",
       "      <th>5115</th>\n",
       "      <th>5116</th>\n",
       "      <th>5117</th>\n",
       "      <th>5118</th>\n",
       "      <th>5119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.610516</td>\n",
       "      <td>-0.518549</td>\n",
       "      <td>-0.452059</td>\n",
       "      <td>-0.265185</td>\n",
       "      <td>-0.397303</td>\n",
       "      <td>1.114940</td>\n",
       "      <td>3.666932</td>\n",
       "      <td>-0.400477</td>\n",
       "      <td>-0.562985</td>\n",
       "      <td>0.369841</td>\n",
       "      <td>...</td>\n",
       "      <td>1.092467</td>\n",
       "      <td>-0.351205</td>\n",
       "      <td>-0.393607</td>\n",
       "      <td>0.313630</td>\n",
       "      <td>1.553586</td>\n",
       "      <td>0.290339</td>\n",
       "      <td>-0.092980</td>\n",
       "      <td>-0.385196</td>\n",
       "      <td>0.134261</td>\n",
       "      <td>-0.097083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.608295</td>\n",
       "      <td>-0.383394</td>\n",
       "      <td>0.307817</td>\n",
       "      <td>-0.462313</td>\n",
       "      <td>-0.302614</td>\n",
       "      <td>0.299457</td>\n",
       "      <td>-0.546535</td>\n",
       "      <td>-0.473610</td>\n",
       "      <td>-0.074286</td>\n",
       "      <td>0.325373</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.423552</td>\n",
       "      <td>-0.414728</td>\n",
       "      <td>-0.397494</td>\n",
       "      <td>-0.275338</td>\n",
       "      <td>-0.400928</td>\n",
       "      <td>0.335066</td>\n",
       "      <td>0.530567</td>\n",
       "      <td>-0.416553</td>\n",
       "      <td>5.362681</td>\n",
       "      <td>-0.377197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.167434</td>\n",
       "      <td>-0.427796</td>\n",
       "      <td>-0.291492</td>\n",
       "      <td>2.438769</td>\n",
       "      <td>-0.017078</td>\n",
       "      <td>-0.421393</td>\n",
       "      <td>-0.529803</td>\n",
       "      <td>-0.452286</td>\n",
       "      <td>-0.587074</td>\n",
       "      <td>1.397641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.425402</td>\n",
       "      <td>0.401038</td>\n",
       "      <td>-0.406348</td>\n",
       "      <td>5.906297</td>\n",
       "      <td>-0.284166</td>\n",
       "      <td>-0.367994</td>\n",
       "      <td>-0.321668</td>\n",
       "      <td>-0.421250</td>\n",
       "      <td>1.362752</td>\n",
       "      <td>-0.412072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.554265</td>\n",
       "      <td>3.396652</td>\n",
       "      <td>-0.455674</td>\n",
       "      <td>0.381851</td>\n",
       "      <td>0.628229</td>\n",
       "      <td>-0.285813</td>\n",
       "      <td>-0.539303</td>\n",
       "      <td>-0.456023</td>\n",
       "      <td>1.394042</td>\n",
       "      <td>-0.573621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426206</td>\n",
       "      <td>-0.410092</td>\n",
       "      <td>-0.406726</td>\n",
       "      <td>-0.416862</td>\n",
       "      <td>6.424712</td>\n",
       "      <td>-0.366428</td>\n",
       "      <td>-0.403894</td>\n",
       "      <td>-0.416553</td>\n",
       "      <td>-0.379059</td>\n",
       "      <td>2.283465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.304883</td>\n",
       "      <td>0.114317</td>\n",
       "      <td>-0.455674</td>\n",
       "      <td>0.862979</td>\n",
       "      <td>-0.414289</td>\n",
       "      <td>2.773452</td>\n",
       "      <td>-0.547210</td>\n",
       "      <td>-0.130294</td>\n",
       "      <td>-0.578454</td>\n",
       "      <td>-0.424471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.421944</td>\n",
       "      <td>-0.137523</td>\n",
       "      <td>2.516734</td>\n",
       "      <td>-0.375081</td>\n",
       "      <td>-0.416320</td>\n",
       "      <td>0.649892</td>\n",
       "      <td>-0.389525</td>\n",
       "      <td>-0.421694</td>\n",
       "      <td>-0.379059</td>\n",
       "      <td>-0.181811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>1.308816</td>\n",
       "      <td>2.135222</td>\n",
       "      <td>1.963891</td>\n",
       "      <td>0.313674</td>\n",
       "      <td>-0.420226</td>\n",
       "      <td>-0.489443</td>\n",
       "      <td>3.207248</td>\n",
       "      <td>-0.449574</td>\n",
       "      <td>-0.579532</td>\n",
       "      <td>4.059415</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426206</td>\n",
       "      <td>-0.384219</td>\n",
       "      <td>-0.403163</td>\n",
       "      <td>-0.422305</td>\n",
       "      <td>-0.416983</td>\n",
       "      <td>-0.357371</td>\n",
       "      <td>-0.372821</td>\n",
       "      <td>-0.412490</td>\n",
       "      <td>-0.378272</td>\n",
       "      <td>0.375296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>-0.237224</td>\n",
       "      <td>-0.386148</td>\n",
       "      <td>-0.455674</td>\n",
       "      <td>-0.458303</td>\n",
       "      <td>-0.418874</td>\n",
       "      <td>-0.320022</td>\n",
       "      <td>0.028867</td>\n",
       "      <td>-0.305579</td>\n",
       "      <td>-0.415914</td>\n",
       "      <td>-0.189471</td>\n",
       "      <td>...</td>\n",
       "      <td>1.638359</td>\n",
       "      <td>-0.278850</td>\n",
       "      <td>-0.358622</td>\n",
       "      <td>-0.027526</td>\n",
       "      <td>-0.416983</td>\n",
       "      <td>-0.370398</td>\n",
       "      <td>-0.401499</td>\n",
       "      <td>0.437887</td>\n",
       "      <td>-0.348549</td>\n",
       "      <td>0.969220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>-0.613008</td>\n",
       "      <td>-0.425673</td>\n",
       "      <td>-0.455674</td>\n",
       "      <td>1.149509</td>\n",
       "      <td>-0.291270</td>\n",
       "      <td>-0.494848</td>\n",
       "      <td>2.190181</td>\n",
       "      <td>2.077407</td>\n",
       "      <td>-0.587074</td>\n",
       "      <td>-0.570661</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.295221</td>\n",
       "      <td>-0.407774</td>\n",
       "      <td>-0.400733</td>\n",
       "      <td>0.232424</td>\n",
       "      <td>-0.409619</td>\n",
       "      <td>-0.370566</td>\n",
       "      <td>-0.401622</td>\n",
       "      <td>0.379363</td>\n",
       "      <td>-0.369072</td>\n",
       "      <td>-0.352028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>0.052104</td>\n",
       "      <td>-0.487916</td>\n",
       "      <td>1.672531</td>\n",
       "      <td>0.710089</td>\n",
       "      <td>-0.413290</td>\n",
       "      <td>-0.498847</td>\n",
       "      <td>0.255522</td>\n",
       "      <td>-0.141726</td>\n",
       "      <td>1.503326</td>\n",
       "      <td>0.323799</td>\n",
       "      <td>...</td>\n",
       "      <td>1.154461</td>\n",
       "      <td>-0.244082</td>\n",
       "      <td>-0.406348</td>\n",
       "      <td>0.322457</td>\n",
       "      <td>-0.416320</td>\n",
       "      <td>0.093873</td>\n",
       "      <td>-0.397938</td>\n",
       "      <td>-0.418330</td>\n",
       "      <td>-0.379059</td>\n",
       "      <td>-0.258703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>-0.611220</td>\n",
       "      <td>0.620863</td>\n",
       "      <td>-0.245909</td>\n",
       "      <td>-0.472678</td>\n",
       "      <td>0.096419</td>\n",
       "      <td>-0.431760</td>\n",
       "      <td>-0.525022</td>\n",
       "      <td>-0.409710</td>\n",
       "      <td>-0.562062</td>\n",
       "      <td>-0.574125</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007118</td>\n",
       "      <td>-0.414540</td>\n",
       "      <td>0.414935</td>\n",
       "      <td>-0.377877</td>\n",
       "      <td>-0.035514</td>\n",
       "      <td>-0.327348</td>\n",
       "      <td>-0.341871</td>\n",
       "      <td>-0.413570</td>\n",
       "      <td>0.986412</td>\n",
       "      <td>-0.411587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5010 rows × 5120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0    -0.610516 -0.518549 -0.452059 -0.265185 -0.397303  1.114940  3.666932   \n",
       "1    -0.608295 -0.383394  0.307817 -0.462313 -0.302614  0.299457 -0.546535   \n",
       "2     0.167434 -0.427796 -0.291492  2.438769 -0.017078 -0.421393 -0.529803   \n",
       "3     1.554265  3.396652 -0.455674  0.381851  0.628229 -0.285813 -0.539303   \n",
       "4    -0.304883  0.114317 -0.455674  0.862979 -0.414289  2.773452 -0.547210   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5005  1.308816  2.135222  1.963891  0.313674 -0.420226 -0.489443  3.207248   \n",
       "5006 -0.237224 -0.386148 -0.455674 -0.458303 -0.418874 -0.320022  0.028867   \n",
       "5007 -0.613008 -0.425673 -0.455674  1.149509 -0.291270 -0.494848  2.190181   \n",
       "5008  0.052104 -0.487916  1.672531  0.710089 -0.413290 -0.498847  0.255522   \n",
       "5009 -0.611220  0.620863 -0.245909 -0.472678  0.096419 -0.431760 -0.525022   \n",
       "\n",
       "          7         8         9     ...      5110      5111      5112  \\\n",
       "0    -0.400477 -0.562985  0.369841  ...  1.092467 -0.351205 -0.393607   \n",
       "1    -0.473610 -0.074286  0.325373  ... -0.423552 -0.414728 -0.397494   \n",
       "2    -0.452286 -0.587074  1.397641  ... -0.425402  0.401038 -0.406348   \n",
       "3    -0.456023  1.394042 -0.573621  ... -0.426206 -0.410092 -0.406726   \n",
       "4    -0.130294 -0.578454 -0.424471  ... -0.421944 -0.137523  2.516734   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5005 -0.449574 -0.579532  4.059415  ... -0.426206 -0.384219 -0.403163   \n",
       "5006 -0.305579 -0.415914 -0.189471  ...  1.638359 -0.278850 -0.358622   \n",
       "5007  2.077407 -0.587074 -0.570661  ... -0.295221 -0.407774 -0.400733   \n",
       "5008 -0.141726  1.503326  0.323799  ...  1.154461 -0.244082 -0.406348   \n",
       "5009 -0.409710 -0.562062 -0.574125  ... -0.007118 -0.414540  0.414935   \n",
       "\n",
       "          5113      5114      5115      5116      5117      5118      5119  \n",
       "0     0.313630  1.553586  0.290339 -0.092980 -0.385196  0.134261 -0.097083  \n",
       "1    -0.275338 -0.400928  0.335066  0.530567 -0.416553  5.362681 -0.377197  \n",
       "2     5.906297 -0.284166 -0.367994 -0.321668 -0.421250  1.362752 -0.412072  \n",
       "3    -0.416862  6.424712 -0.366428 -0.403894 -0.416553 -0.379059  2.283465  \n",
       "4    -0.375081 -0.416320  0.649892 -0.389525 -0.421694 -0.379059 -0.181811  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5005 -0.422305 -0.416983 -0.357371 -0.372821 -0.412490 -0.378272  0.375296  \n",
       "5006 -0.027526 -0.416983 -0.370398 -0.401499  0.437887 -0.348549  0.969220  \n",
       "5007  0.232424 -0.409619 -0.370566 -0.401622  0.379363 -0.369072 -0.352028  \n",
       "5008  0.322457 -0.416320  0.093873 -0.397938 -0.418330 -0.379059 -0.258703  \n",
       "5009 -0.377877 -0.035514 -0.327348 -0.341871 -0.413570  0.986412 -0.411587  \n",
       "\n",
       "[5010 rows x 5120 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "x_data = ss.fit_transform(x_data)\n",
    "x_data = pd.DataFrame(x_data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SVC(kernel = \"linear\")\n",
    "selector = RFE(estimator,n_features_to_select = 200,step = 64)\n",
    "selector = selector.fit(x_data,y_data)\n",
    "rank = selector.ranking_\n",
    "rank = pd.DataFrame(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank.columns = ['rank']\n",
    "rank.to_csv('/home/zourui/data/predict_user_attribute20200911/raw_data/age/rank/gender_rank.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5120 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rank\n",
       "0       56\n",
       "1       58\n",
       "2       25\n",
       "3       41\n",
       "4       39\n",
       "...    ...\n",
       "5115    14\n",
       "5116    10\n",
       "5117    35\n",
       "5118    68\n",
       "5119    12\n",
       "\n",
       "[5120 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>5000</th>\n",
       "      <th>5001</th>\n",
       "      <th>5002</th>\n",
       "      <th>5003</th>\n",
       "      <th>5004</th>\n",
       "      <th>5005</th>\n",
       "      <th>5006</th>\n",
       "      <th>5007</th>\n",
       "      <th>5008</th>\n",
       "      <th>5009</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>-0.610516</td>\n",
       "      <td>-0.608295</td>\n",
       "      <td>0.167434</td>\n",
       "      <td>1.554265</td>\n",
       "      <td>-0.304883</td>\n",
       "      <td>-0.608295</td>\n",
       "      <td>0.211420</td>\n",
       "      <td>3.379665</td>\n",
       "      <td>-0.613008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.610083</td>\n",
       "      <td>0.069330</td>\n",
       "      <td>-0.452499</td>\n",
       "      <td>-0.613008</td>\n",
       "      <td>-0.241070</td>\n",
       "      <td>1.308816</td>\n",
       "      <td>-0.237224</td>\n",
       "      <td>-0.613008</td>\n",
       "      <td>0.052104</td>\n",
       "      <td>-0.611220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>-0.518549</td>\n",
       "      <td>-0.383394</td>\n",
       "      <td>-0.427796</td>\n",
       "      <td>3.396652</td>\n",
       "      <td>0.114317</td>\n",
       "      <td>-0.383394</td>\n",
       "      <td>0.112711</td>\n",
       "      <td>-0.124499</td>\n",
       "      <td>-0.518148</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>1.931341</td>\n",
       "      <td>-0.517976</td>\n",
       "      <td>0.192852</td>\n",
       "      <td>-0.517918</td>\n",
       "      <td>2.135222</td>\n",
       "      <td>-0.386148</td>\n",
       "      <td>-0.425673</td>\n",
       "      <td>-0.487916</td>\n",
       "      <td>0.620863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>-0.452059</td>\n",
       "      <td>0.307817</td>\n",
       "      <td>-0.291492</td>\n",
       "      <td>-0.455674</td>\n",
       "      <td>-0.455674</td>\n",
       "      <td>0.307817</td>\n",
       "      <td>-0.447309</td>\n",
       "      <td>-0.382302</td>\n",
       "      <td>-0.142551</td>\n",
       "      <td>...</td>\n",
       "      <td>1.424556</td>\n",
       "      <td>-0.456312</td>\n",
       "      <td>-0.431075</td>\n",
       "      <td>-0.456383</td>\n",
       "      <td>-0.080309</td>\n",
       "      <td>1.963891</td>\n",
       "      <td>-0.455674</td>\n",
       "      <td>-0.455674</td>\n",
       "      <td>1.672531</td>\n",
       "      <td>-0.245909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>-0.265185</td>\n",
       "      <td>-0.462313</td>\n",
       "      <td>2.438769</td>\n",
       "      <td>0.381851</td>\n",
       "      <td>0.862979</td>\n",
       "      <td>-0.462313</td>\n",
       "      <td>-0.444729</td>\n",
       "      <td>-0.270429</td>\n",
       "      <td>-0.473234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.472678</td>\n",
       "      <td>-0.456575</td>\n",
       "      <td>-0.058494</td>\n",
       "      <td>-0.453305</td>\n",
       "      <td>-0.291962</td>\n",
       "      <td>0.313674</td>\n",
       "      <td>-0.458303</td>\n",
       "      <td>1.149509</td>\n",
       "      <td>0.710089</td>\n",
       "      <td>-0.472678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>-0.397303</td>\n",
       "      <td>-0.302614</td>\n",
       "      <td>-0.017078</td>\n",
       "      <td>0.628229</td>\n",
       "      <td>-0.414289</td>\n",
       "      <td>-0.302614</td>\n",
       "      <td>1.983672</td>\n",
       "      <td>-0.401770</td>\n",
       "      <td>4.710487</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312723</td>\n",
       "      <td>0.821779</td>\n",
       "      <td>-0.393600</td>\n",
       "      <td>-0.420872</td>\n",
       "      <td>-0.420402</td>\n",
       "      <td>-0.420226</td>\n",
       "      <td>-0.418874</td>\n",
       "      <td>-0.291270</td>\n",
       "      <td>-0.413290</td>\n",
       "      <td>0.096419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>14</td>\n",
       "      <td>0.290339</td>\n",
       "      <td>0.335066</td>\n",
       "      <td>-0.367994</td>\n",
       "      <td>-0.366428</td>\n",
       "      <td>0.649892</td>\n",
       "      <td>-0.328186</td>\n",
       "      <td>-0.370006</td>\n",
       "      <td>-0.371013</td>\n",
       "      <td>-0.355135</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.370006</td>\n",
       "      <td>-0.293858</td>\n",
       "      <td>-0.310295</td>\n",
       "      <td>-0.359216</td>\n",
       "      <td>-0.116737</td>\n",
       "      <td>-0.357371</td>\n",
       "      <td>-0.370398</td>\n",
       "      <td>-0.370566</td>\n",
       "      <td>0.093873</td>\n",
       "      <td>-0.327348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.092980</td>\n",
       "      <td>0.530567</td>\n",
       "      <td>-0.321668</td>\n",
       "      <td>-0.403894</td>\n",
       "      <td>-0.389525</td>\n",
       "      <td>0.674817</td>\n",
       "      <td>0.546042</td>\n",
       "      <td>-0.403956</td>\n",
       "      <td>-0.403464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010126</td>\n",
       "      <td>-0.388972</td>\n",
       "      <td>-0.387744</td>\n",
       "      <td>-0.396034</td>\n",
       "      <td>-0.119755</td>\n",
       "      <td>-0.372821</td>\n",
       "      <td>-0.401499</td>\n",
       "      <td>-0.401622</td>\n",
       "      <td>-0.397938</td>\n",
       "      <td>-0.341871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>35</td>\n",
       "      <td>-0.385196</td>\n",
       "      <td>-0.416553</td>\n",
       "      <td>-0.421250</td>\n",
       "      <td>-0.416553</td>\n",
       "      <td>-0.421694</td>\n",
       "      <td>-0.348825</td>\n",
       "      <td>3.604159</td>\n",
       "      <td>-0.421758</td>\n",
       "      <td>-0.172998</td>\n",
       "      <td>...</td>\n",
       "      <td>2.883779</td>\n",
       "      <td>-0.397193</td>\n",
       "      <td>-0.410713</td>\n",
       "      <td>-0.105461</td>\n",
       "      <td>-0.421060</td>\n",
       "      <td>-0.412490</td>\n",
       "      <td>0.437887</td>\n",
       "      <td>0.379363</td>\n",
       "      <td>-0.418330</td>\n",
       "      <td>-0.413570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>68</td>\n",
       "      <td>0.134261</td>\n",
       "      <td>5.362681</td>\n",
       "      <td>1.362752</td>\n",
       "      <td>-0.379059</td>\n",
       "      <td>-0.379059</td>\n",
       "      <td>1.058912</td>\n",
       "      <td>0.287282</td>\n",
       "      <td>-0.379137</td>\n",
       "      <td>-0.099045</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.378508</td>\n",
       "      <td>-0.378272</td>\n",
       "      <td>-0.378272</td>\n",
       "      <td>-0.378272</td>\n",
       "      <td>-0.168478</td>\n",
       "      <td>-0.378272</td>\n",
       "      <td>-0.348549</td>\n",
       "      <td>-0.369072</td>\n",
       "      <td>-0.379059</td>\n",
       "      <td>0.986412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>12</td>\n",
       "      <td>-0.097083</td>\n",
       "      <td>-0.377197</td>\n",
       "      <td>-0.412072</td>\n",
       "      <td>2.283465</td>\n",
       "      <td>-0.181811</td>\n",
       "      <td>-0.407219</td>\n",
       "      <td>-0.395016</td>\n",
       "      <td>-0.412835</td>\n",
       "      <td>-0.282138</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.394045</td>\n",
       "      <td>0.827707</td>\n",
       "      <td>-0.407635</td>\n",
       "      <td>-0.407011</td>\n",
       "      <td>0.575744</td>\n",
       "      <td>0.375296</td>\n",
       "      <td>0.969220</td>\n",
       "      <td>-0.352028</td>\n",
       "      <td>-0.258703</td>\n",
       "      <td>-0.411587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5120 rows × 5011 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rank         0         1         2         3         4         5  \\\n",
       "0       56 -0.610516 -0.608295  0.167434  1.554265 -0.304883 -0.608295   \n",
       "1       58 -0.518549 -0.383394 -0.427796  3.396652  0.114317 -0.383394   \n",
       "2       25 -0.452059  0.307817 -0.291492 -0.455674 -0.455674  0.307817   \n",
       "3       41 -0.265185 -0.462313  2.438769  0.381851  0.862979 -0.462313   \n",
       "4       39 -0.397303 -0.302614 -0.017078  0.628229 -0.414289 -0.302614   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "5115    14  0.290339  0.335066 -0.367994 -0.366428  0.649892 -0.328186   \n",
       "5116    10 -0.092980  0.530567 -0.321668 -0.403894 -0.389525  0.674817   \n",
       "5117    35 -0.385196 -0.416553 -0.421250 -0.416553 -0.421694 -0.348825   \n",
       "5118    68  0.134261  5.362681  1.362752 -0.379059 -0.379059  1.058912   \n",
       "5119    12 -0.097083 -0.377197 -0.412072  2.283465 -0.181811 -0.407219   \n",
       "\n",
       "             6         7         8  ...      5000      5001      5002  \\\n",
       "0     0.211420  3.379665 -0.613008  ... -0.610083  0.069330 -0.452499   \n",
       "1     0.112711 -0.124499 -0.518148  ... -0.412995  1.931341 -0.517976   \n",
       "2    -0.447309 -0.382302 -0.142551  ...  1.424556 -0.456312 -0.431075   \n",
       "3    -0.444729 -0.270429 -0.473234  ... -0.472678 -0.456575 -0.058494   \n",
       "4     1.983672 -0.401770  4.710487  ... -0.312723  0.821779 -0.393600   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5115 -0.370006 -0.371013 -0.355135  ... -0.370006 -0.293858 -0.310295   \n",
       "5116  0.546042 -0.403956 -0.403464  ...  0.010126 -0.388972 -0.387744   \n",
       "5117  3.604159 -0.421758 -0.172998  ...  2.883779 -0.397193 -0.410713   \n",
       "5118  0.287282 -0.379137 -0.099045  ... -0.378508 -0.378272 -0.378272   \n",
       "5119 -0.395016 -0.412835 -0.282138  ... -0.394045  0.827707 -0.407635   \n",
       "\n",
       "          5003      5004      5005      5006      5007      5008      5009  \n",
       "0    -0.613008 -0.241070  1.308816 -0.237224 -0.613008  0.052104 -0.611220  \n",
       "1     0.192852 -0.517918  2.135222 -0.386148 -0.425673 -0.487916  0.620863  \n",
       "2    -0.456383 -0.080309  1.963891 -0.455674 -0.455674  1.672531 -0.245909  \n",
       "3    -0.453305 -0.291962  0.313674 -0.458303  1.149509  0.710089 -0.472678  \n",
       "4    -0.420872 -0.420402 -0.420226 -0.418874 -0.291270 -0.413290  0.096419  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5115 -0.359216 -0.116737 -0.357371 -0.370398 -0.370566  0.093873 -0.327348  \n",
       "5116 -0.396034 -0.119755 -0.372821 -0.401499 -0.401622 -0.397938 -0.341871  \n",
       "5117 -0.105461 -0.421060 -0.412490  0.437887  0.379363 -0.418330 -0.413570  \n",
       "5118 -0.378272 -0.168478 -0.378272 -0.348549 -0.369072 -0.379059  0.986412  \n",
       "5119 -0.407011  0.575744  0.375296  0.969220 -0.352028 -0.258703 -0.411587  \n",
       "\n",
       "[5120 rows x 5011 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_T = x_data.T\n",
    "rank_data = pd.merge(rank,x_T,on = rank.index)\n",
    "rank_data = rank_data.drop('key_0',axis = 1)\n",
    "rank_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>17</th>\n",
       "      <th>23</th>\n",
       "      <th>40</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>92</th>\n",
       "      <th>94</th>\n",
       "      <th>106</th>\n",
       "      <th>110</th>\n",
       "      <th>...</th>\n",
       "      <th>4923</th>\n",
       "      <th>4925</th>\n",
       "      <th>4926</th>\n",
       "      <th>4979</th>\n",
       "      <th>4990</th>\n",
       "      <th>5005</th>\n",
       "      <th>5047</th>\n",
       "      <th>5065</th>\n",
       "      <th>5066</th>\n",
       "      <th>5104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.353833</td>\n",
       "      <td>-0.011943</td>\n",
       "      <td>1.669264</td>\n",
       "      <td>0.192065</td>\n",
       "      <td>-0.455865</td>\n",
       "      <td>-0.578191</td>\n",
       "      <td>-0.384625</td>\n",
       "      <td>-0.410590</td>\n",
       "      <td>0.169195</td>\n",
       "      <td>-0.442192</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.387930</td>\n",
       "      <td>-0.376418</td>\n",
       "      <td>-0.362028</td>\n",
       "      <td>-0.435021</td>\n",
       "      <td>-0.375088</td>\n",
       "      <td>-0.165503</td>\n",
       "      <td>-0.440385</td>\n",
       "      <td>-0.395481</td>\n",
       "      <td>1.325651</td>\n",
       "      <td>-0.355551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.423837</td>\n",
       "      <td>-0.352634</td>\n",
       "      <td>-0.379972</td>\n",
       "      <td>3.192932</td>\n",
       "      <td>-0.459455</td>\n",
       "      <td>0.769191</td>\n",
       "      <td>0.411713</td>\n",
       "      <td>-0.006677</td>\n",
       "      <td>-0.354917</td>\n",
       "      <td>-0.441089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409749</td>\n",
       "      <td>-0.253760</td>\n",
       "      <td>-0.383963</td>\n",
       "      <td>-0.443817</td>\n",
       "      <td>0.856879</td>\n",
       "      <td>-0.389722</td>\n",
       "      <td>-0.439958</td>\n",
       "      <td>-0.404168</td>\n",
       "      <td>4.656676</td>\n",
       "      <td>-0.365593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.545760</td>\n",
       "      <td>0.436461</td>\n",
       "      <td>-0.414150</td>\n",
       "      <td>-0.456264</td>\n",
       "      <td>0.177456</td>\n",
       "      <td>-0.421243</td>\n",
       "      <td>-0.389302</td>\n",
       "      <td>-0.371292</td>\n",
       "      <td>-0.233455</td>\n",
       "      <td>-0.398126</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.390593</td>\n",
       "      <td>-0.365236</td>\n",
       "      <td>-0.384180</td>\n",
       "      <td>2.682007</td>\n",
       "      <td>-0.272430</td>\n",
       "      <td>-0.287306</td>\n",
       "      <td>-0.440385</td>\n",
       "      <td>-0.391137</td>\n",
       "      <td>-0.339940</td>\n",
       "      <td>-0.361928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.554240</td>\n",
       "      <td>-0.102187</td>\n",
       "      <td>-0.413629</td>\n",
       "      <td>-0.425594</td>\n",
       "      <td>-0.366637</td>\n",
       "      <td>-0.526933</td>\n",
       "      <td>-0.388887</td>\n",
       "      <td>-0.354065</td>\n",
       "      <td>-0.382702</td>\n",
       "      <td>-0.450629</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.394027</td>\n",
       "      <td>-0.419820</td>\n",
       "      <td>-0.391059</td>\n",
       "      <td>-0.135868</td>\n",
       "      <td>-0.351779</td>\n",
       "      <td>0.184289</td>\n",
       "      <td>-0.386650</td>\n",
       "      <td>-0.404389</td>\n",
       "      <td>-0.355737</td>\n",
       "      <td>-0.253945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.501456</td>\n",
       "      <td>-0.374160</td>\n",
       "      <td>-0.414150</td>\n",
       "      <td>-0.020804</td>\n",
       "      <td>-0.459953</td>\n",
       "      <td>-0.572966</td>\n",
       "      <td>-0.385099</td>\n",
       "      <td>0.264963</td>\n",
       "      <td>-0.373969</td>\n",
       "      <td>-0.242433</td>\n",
       "      <td>...</td>\n",
       "      <td>1.377112</td>\n",
       "      <td>-0.271722</td>\n",
       "      <td>-0.391795</td>\n",
       "      <td>-0.444576</td>\n",
       "      <td>-0.395889</td>\n",
       "      <td>-0.395340</td>\n",
       "      <td>-0.379696</td>\n",
       "      <td>-0.395481</td>\n",
       "      <td>4.525393</td>\n",
       "      <td>-0.363404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>1.889066</td>\n",
       "      <td>-0.370600</td>\n",
       "      <td>-0.305103</td>\n",
       "      <td>1.347605</td>\n",
       "      <td>-0.257370</td>\n",
       "      <td>1.679064</td>\n",
       "      <td>-0.364558</td>\n",
       "      <td>-0.429315</td>\n",
       "      <td>0.481820</td>\n",
       "      <td>1.416583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.364029</td>\n",
       "      <td>2.936814</td>\n",
       "      <td>-0.368474</td>\n",
       "      <td>-0.418793</td>\n",
       "      <td>-0.383959</td>\n",
       "      <td>-0.370267</td>\n",
       "      <td>-0.321020</td>\n",
       "      <td>1.113245</td>\n",
       "      <td>6.410515</td>\n",
       "      <td>-0.365736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>0.292991</td>\n",
       "      <td>-0.365798</td>\n",
       "      <td>-0.390861</td>\n",
       "      <td>-0.456891</td>\n",
       "      <td>-0.447690</td>\n",
       "      <td>-0.404245</td>\n",
       "      <td>-0.358580</td>\n",
       "      <td>-0.427018</td>\n",
       "      <td>-0.382226</td>\n",
       "      <td>-0.288317</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.391855</td>\n",
       "      <td>-0.416116</td>\n",
       "      <td>4.411126</td>\n",
       "      <td>-0.442073</td>\n",
       "      <td>-0.388242</td>\n",
       "      <td>-0.398628</td>\n",
       "      <td>0.568819</td>\n",
       "      <td>-0.403653</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>-0.277360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>-0.554154</td>\n",
       "      <td>1.157748</td>\n",
       "      <td>-0.337770</td>\n",
       "      <td>-0.014469</td>\n",
       "      <td>1.747277</td>\n",
       "      <td>-0.578389</td>\n",
       "      <td>-0.311402</td>\n",
       "      <td>-0.403150</td>\n",
       "      <td>0.317331</td>\n",
       "      <td>-0.449526</td>\n",
       "      <td>...</td>\n",
       "      <td>1.242893</td>\n",
       "      <td>-0.411573</td>\n",
       "      <td>-0.386992</td>\n",
       "      <td>-0.443817</td>\n",
       "      <td>-0.266312</td>\n",
       "      <td>-0.396504</td>\n",
       "      <td>-0.433310</td>\n",
       "      <td>-0.385983</td>\n",
       "      <td>-0.182431</td>\n",
       "      <td>-0.360786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>-0.555105</td>\n",
       "      <td>-0.370352</td>\n",
       "      <td>0.052571</td>\n",
       "      <td>-0.338477</td>\n",
       "      <td>-0.448189</td>\n",
       "      <td>-0.146965</td>\n",
       "      <td>-0.149210</td>\n",
       "      <td>-0.425121</td>\n",
       "      <td>-0.256080</td>\n",
       "      <td>-0.385146</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.397952</td>\n",
       "      <td>0.467021</td>\n",
       "      <td>-0.391362</td>\n",
       "      <td>0.323743</td>\n",
       "      <td>1.597883</td>\n",
       "      <td>3.185463</td>\n",
       "      <td>-0.420257</td>\n",
       "      <td>-0.381051</td>\n",
       "      <td>-0.137295</td>\n",
       "      <td>-0.340417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>-0.550260</td>\n",
       "      <td>0.162914</td>\n",
       "      <td>0.099618</td>\n",
       "      <td>-0.394799</td>\n",
       "      <td>-0.311156</td>\n",
       "      <td>0.270041</td>\n",
       "      <td>0.289832</td>\n",
       "      <td>-0.425820</td>\n",
       "      <td>-0.381908</td>\n",
       "      <td>-0.449980</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125588</td>\n",
       "      <td>-0.410874</td>\n",
       "      <td>0.224617</td>\n",
       "      <td>-0.404461</td>\n",
       "      <td>-0.394849</td>\n",
       "      <td>-0.359648</td>\n",
       "      <td>-0.440568</td>\n",
       "      <td>0.112729</td>\n",
       "      <td>-0.370290</td>\n",
       "      <td>-0.365593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5010 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          17        23        40        65        66        67        92    \\\n",
       "0    -0.353833 -0.011943  1.669264  0.192065 -0.455865 -0.578191 -0.384625   \n",
       "1    -0.423837 -0.352634 -0.379972  3.192932 -0.459455  0.769191  0.411713   \n",
       "2    -0.545760  0.436461 -0.414150 -0.456264  0.177456 -0.421243 -0.389302   \n",
       "3    -0.554240 -0.102187 -0.413629 -0.425594 -0.366637 -0.526933 -0.388887   \n",
       "4    -0.501456 -0.374160 -0.414150 -0.020804 -0.459953 -0.572966 -0.385099   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5005  1.889066 -0.370600 -0.305103  1.347605 -0.257370  1.679064 -0.364558   \n",
       "5006  0.292991 -0.365798 -0.390861 -0.456891 -0.447690 -0.404245 -0.358580   \n",
       "5007 -0.554154  1.157748 -0.337770 -0.014469  1.747277 -0.578389 -0.311402   \n",
       "5008 -0.555105 -0.370352  0.052571 -0.338477 -0.448189 -0.146965 -0.149210   \n",
       "5009 -0.550260  0.162914  0.099618 -0.394799 -0.311156  0.270041  0.289832   \n",
       "\n",
       "          94        106       110   ...      4923      4925      4926  \\\n",
       "0    -0.410590  0.169195 -0.442192  ... -0.387930 -0.376418 -0.362028   \n",
       "1    -0.006677 -0.354917 -0.441089  ...  0.409749 -0.253760 -0.383963   \n",
       "2    -0.371292 -0.233455 -0.398126  ... -0.390593 -0.365236 -0.384180   \n",
       "3    -0.354065 -0.382702 -0.450629  ... -0.394027 -0.419820 -0.391059   \n",
       "4     0.264963 -0.373969 -0.242433  ...  1.377112 -0.271722 -0.391795   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5005 -0.429315  0.481820  1.416583  ... -0.364029  2.936814 -0.368474   \n",
       "5006 -0.427018 -0.382226 -0.288317  ... -0.391855 -0.416116  4.411126   \n",
       "5007 -0.403150  0.317331 -0.449526  ...  1.242893 -0.411573 -0.386992   \n",
       "5008 -0.425121 -0.256080 -0.385146  ... -0.397952  0.467021 -0.391362   \n",
       "5009 -0.425820 -0.381908 -0.449980  ... -0.125588 -0.410874  0.224617   \n",
       "\n",
       "          4979      4990      5005      5047      5065      5066      5104  \n",
       "0    -0.435021 -0.375088 -0.165503 -0.440385 -0.395481  1.325651 -0.355551  \n",
       "1    -0.443817  0.856879 -0.389722 -0.439958 -0.404168  4.656676 -0.365593  \n",
       "2     2.682007 -0.272430 -0.287306 -0.440385 -0.391137 -0.339940 -0.361928  \n",
       "3    -0.135868 -0.351779  0.184289 -0.386650 -0.404389 -0.355737 -0.253945  \n",
       "4    -0.444576 -0.395889 -0.395340 -0.379696 -0.395481  4.525393 -0.363404  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5005 -0.418793 -0.383959 -0.370267 -0.321020  1.113245  6.410515 -0.365736  \n",
       "5006 -0.442073 -0.388242 -0.398628  0.568819 -0.403653 -0.366087 -0.277360  \n",
       "5007 -0.443817 -0.266312 -0.396504 -0.433310 -0.385983 -0.182431 -0.360786  \n",
       "5008  0.323743  1.597883  3.185463 -0.420257 -0.381051 -0.137295 -0.340417  \n",
       "5009 -0.404461 -0.394849 -0.359648 -0.440568  0.112729 -0.370290 -0.365593  \n",
       "\n",
       "[5010 rows x 200 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_data_200 = rank_data.groupby(rank_data.index).filter(lambda x : float(x['rank'])==1)\n",
    "rank_data_200 = rank_data_200.drop('rank',axis = 1)\n",
    "rank_data_200 = rank_data_200.T\n",
    "rank_data_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>17</th>\n",
       "      <th>23</th>\n",
       "      <th>40</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>92</th>\n",
       "      <th>94</th>\n",
       "      <th>106</th>\n",
       "      <th>...</th>\n",
       "      <th>4923</th>\n",
       "      <th>4925</th>\n",
       "      <th>4926</th>\n",
       "      <th>4979</th>\n",
       "      <th>4990</th>\n",
       "      <th>5005</th>\n",
       "      <th>5047</th>\n",
       "      <th>5065</th>\n",
       "      <th>5066</th>\n",
       "      <th>5104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.353833</td>\n",
       "      <td>-0.011943</td>\n",
       "      <td>1.669264</td>\n",
       "      <td>0.192065</td>\n",
       "      <td>-0.455865</td>\n",
       "      <td>-0.578191</td>\n",
       "      <td>-0.384625</td>\n",
       "      <td>-0.410590</td>\n",
       "      <td>0.169195</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.387930</td>\n",
       "      <td>-0.376418</td>\n",
       "      <td>-0.362028</td>\n",
       "      <td>-0.435021</td>\n",
       "      <td>-0.375088</td>\n",
       "      <td>-0.165503</td>\n",
       "      <td>-0.440385</td>\n",
       "      <td>-0.395481</td>\n",
       "      <td>1.325651</td>\n",
       "      <td>-0.355551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.423837</td>\n",
       "      <td>-0.352634</td>\n",
       "      <td>-0.379972</td>\n",
       "      <td>3.192932</td>\n",
       "      <td>-0.459455</td>\n",
       "      <td>0.769191</td>\n",
       "      <td>0.411713</td>\n",
       "      <td>-0.006677</td>\n",
       "      <td>-0.354917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409749</td>\n",
       "      <td>-0.253760</td>\n",
       "      <td>-0.383963</td>\n",
       "      <td>-0.443817</td>\n",
       "      <td>0.856879</td>\n",
       "      <td>-0.389722</td>\n",
       "      <td>-0.439958</td>\n",
       "      <td>-0.404168</td>\n",
       "      <td>4.656676</td>\n",
       "      <td>-0.365593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.545760</td>\n",
       "      <td>0.436461</td>\n",
       "      <td>-0.414150</td>\n",
       "      <td>-0.456264</td>\n",
       "      <td>0.177456</td>\n",
       "      <td>-0.421243</td>\n",
       "      <td>-0.389302</td>\n",
       "      <td>-0.371292</td>\n",
       "      <td>-0.233455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.390593</td>\n",
       "      <td>-0.365236</td>\n",
       "      <td>-0.384180</td>\n",
       "      <td>2.682007</td>\n",
       "      <td>-0.272430</td>\n",
       "      <td>-0.287306</td>\n",
       "      <td>-0.440385</td>\n",
       "      <td>-0.391137</td>\n",
       "      <td>-0.339940</td>\n",
       "      <td>-0.361928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.554240</td>\n",
       "      <td>-0.102187</td>\n",
       "      <td>-0.413629</td>\n",
       "      <td>-0.425594</td>\n",
       "      <td>-0.366637</td>\n",
       "      <td>-0.526933</td>\n",
       "      <td>-0.388887</td>\n",
       "      <td>-0.354065</td>\n",
       "      <td>-0.382702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.394027</td>\n",
       "      <td>-0.419820</td>\n",
       "      <td>-0.391059</td>\n",
       "      <td>-0.135868</td>\n",
       "      <td>-0.351779</td>\n",
       "      <td>0.184289</td>\n",
       "      <td>-0.386650</td>\n",
       "      <td>-0.404389</td>\n",
       "      <td>-0.355737</td>\n",
       "      <td>-0.253945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.501456</td>\n",
       "      <td>-0.374160</td>\n",
       "      <td>-0.414150</td>\n",
       "      <td>-0.020804</td>\n",
       "      <td>-0.459953</td>\n",
       "      <td>-0.572966</td>\n",
       "      <td>-0.385099</td>\n",
       "      <td>0.264963</td>\n",
       "      <td>-0.373969</td>\n",
       "      <td>...</td>\n",
       "      <td>1.377112</td>\n",
       "      <td>-0.271722</td>\n",
       "      <td>-0.391795</td>\n",
       "      <td>-0.444576</td>\n",
       "      <td>-0.395889</td>\n",
       "      <td>-0.395340</td>\n",
       "      <td>-0.379696</td>\n",
       "      <td>-0.395481</td>\n",
       "      <td>4.525393</td>\n",
       "      <td>-0.363404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>1</td>\n",
       "      <td>1.889066</td>\n",
       "      <td>-0.370600</td>\n",
       "      <td>-0.305103</td>\n",
       "      <td>1.347605</td>\n",
       "      <td>-0.257370</td>\n",
       "      <td>1.679064</td>\n",
       "      <td>-0.364558</td>\n",
       "      <td>-0.429315</td>\n",
       "      <td>0.481820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.364029</td>\n",
       "      <td>2.936814</td>\n",
       "      <td>-0.368474</td>\n",
       "      <td>-0.418793</td>\n",
       "      <td>-0.383959</td>\n",
       "      <td>-0.370267</td>\n",
       "      <td>-0.321020</td>\n",
       "      <td>1.113245</td>\n",
       "      <td>6.410515</td>\n",
       "      <td>-0.365736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>1</td>\n",
       "      <td>0.292991</td>\n",
       "      <td>-0.365798</td>\n",
       "      <td>-0.390861</td>\n",
       "      <td>-0.456891</td>\n",
       "      <td>-0.447690</td>\n",
       "      <td>-0.404245</td>\n",
       "      <td>-0.358580</td>\n",
       "      <td>-0.427018</td>\n",
       "      <td>-0.382226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.391855</td>\n",
       "      <td>-0.416116</td>\n",
       "      <td>4.411126</td>\n",
       "      <td>-0.442073</td>\n",
       "      <td>-0.388242</td>\n",
       "      <td>-0.398628</td>\n",
       "      <td>0.568819</td>\n",
       "      <td>-0.403653</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>-0.277360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.554154</td>\n",
       "      <td>1.157748</td>\n",
       "      <td>-0.337770</td>\n",
       "      <td>-0.014469</td>\n",
       "      <td>1.747277</td>\n",
       "      <td>-0.578389</td>\n",
       "      <td>-0.311402</td>\n",
       "      <td>-0.403150</td>\n",
       "      <td>0.317331</td>\n",
       "      <td>...</td>\n",
       "      <td>1.242893</td>\n",
       "      <td>-0.411573</td>\n",
       "      <td>-0.386992</td>\n",
       "      <td>-0.443817</td>\n",
       "      <td>-0.266312</td>\n",
       "      <td>-0.396504</td>\n",
       "      <td>-0.433310</td>\n",
       "      <td>-0.385983</td>\n",
       "      <td>-0.182431</td>\n",
       "      <td>-0.360786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.555105</td>\n",
       "      <td>-0.370352</td>\n",
       "      <td>0.052571</td>\n",
       "      <td>-0.338477</td>\n",
       "      <td>-0.448189</td>\n",
       "      <td>-0.146965</td>\n",
       "      <td>-0.149210</td>\n",
       "      <td>-0.425121</td>\n",
       "      <td>-0.256080</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.397952</td>\n",
       "      <td>0.467021</td>\n",
       "      <td>-0.391362</td>\n",
       "      <td>0.323743</td>\n",
       "      <td>1.597883</td>\n",
       "      <td>3.185463</td>\n",
       "      <td>-0.420257</td>\n",
       "      <td>-0.381051</td>\n",
       "      <td>-0.137295</td>\n",
       "      <td>-0.340417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.550260</td>\n",
       "      <td>0.162914</td>\n",
       "      <td>0.099618</td>\n",
       "      <td>-0.394799</td>\n",
       "      <td>-0.311156</td>\n",
       "      <td>0.270041</td>\n",
       "      <td>0.289832</td>\n",
       "      <td>-0.425820</td>\n",
       "      <td>-0.381908</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125588</td>\n",
       "      <td>-0.410874</td>\n",
       "      <td>0.224617</td>\n",
       "      <td>-0.404461</td>\n",
       "      <td>-0.394849</td>\n",
       "      <td>-0.359648</td>\n",
       "      <td>-0.440568</td>\n",
       "      <td>0.112729</td>\n",
       "      <td>-0.370290</td>\n",
       "      <td>-0.365593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5010 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender        17        23        40        65        66        67  \\\n",
       "0          0 -0.353833 -0.011943  1.669264  0.192065 -0.455865 -0.578191   \n",
       "1          0 -0.423837 -0.352634 -0.379972  3.192932 -0.459455  0.769191   \n",
       "2          0 -0.545760  0.436461 -0.414150 -0.456264  0.177456 -0.421243   \n",
       "3          0 -0.554240 -0.102187 -0.413629 -0.425594 -0.366637 -0.526933   \n",
       "4          0 -0.501456 -0.374160 -0.414150 -0.020804 -0.459953 -0.572966   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "5005       1  1.889066 -0.370600 -0.305103  1.347605 -0.257370  1.679064   \n",
       "5006       1  0.292991 -0.365798 -0.390861 -0.456891 -0.447690 -0.404245   \n",
       "5007       1 -0.554154  1.157748 -0.337770 -0.014469  1.747277 -0.578389   \n",
       "5008       1 -0.555105 -0.370352  0.052571 -0.338477 -0.448189 -0.146965   \n",
       "5009       1 -0.550260  0.162914  0.099618 -0.394799 -0.311156  0.270041   \n",
       "\n",
       "            92        94       106  ...      4923      4925      4926  \\\n",
       "0    -0.384625 -0.410590  0.169195  ... -0.387930 -0.376418 -0.362028   \n",
       "1     0.411713 -0.006677 -0.354917  ...  0.409749 -0.253760 -0.383963   \n",
       "2    -0.389302 -0.371292 -0.233455  ... -0.390593 -0.365236 -0.384180   \n",
       "3    -0.388887 -0.354065 -0.382702  ... -0.394027 -0.419820 -0.391059   \n",
       "4    -0.385099  0.264963 -0.373969  ...  1.377112 -0.271722 -0.391795   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5005 -0.364558 -0.429315  0.481820  ... -0.364029  2.936814 -0.368474   \n",
       "5006 -0.358580 -0.427018 -0.382226  ... -0.391855 -0.416116  4.411126   \n",
       "5007 -0.311402 -0.403150  0.317331  ...  1.242893 -0.411573 -0.386992   \n",
       "5008 -0.149210 -0.425121 -0.256080  ... -0.397952  0.467021 -0.391362   \n",
       "5009  0.289832 -0.425820 -0.381908  ... -0.125588 -0.410874  0.224617   \n",
       "\n",
       "          4979      4990      5005      5047      5065      5066      5104  \n",
       "0    -0.435021 -0.375088 -0.165503 -0.440385 -0.395481  1.325651 -0.355551  \n",
       "1    -0.443817  0.856879 -0.389722 -0.439958 -0.404168  4.656676 -0.365593  \n",
       "2     2.682007 -0.272430 -0.287306 -0.440385 -0.391137 -0.339940 -0.361928  \n",
       "3    -0.135868 -0.351779  0.184289 -0.386650 -0.404389 -0.355737 -0.253945  \n",
       "4    -0.444576 -0.395889 -0.395340 -0.379696 -0.395481  4.525393 -0.363404  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5005 -0.418793 -0.383959 -0.370267 -0.321020  1.113245  6.410515 -0.365736  \n",
       "5006 -0.442073 -0.388242 -0.398628  0.568819 -0.403653 -0.366087 -0.277360  \n",
       "5007 -0.443817 -0.266312 -0.396504 -0.433310 -0.385983 -0.182431 -0.360786  \n",
       "5008  0.323743  1.597883  3.185463 -0.420257 -0.381051 -0.137295 -0.340417  \n",
       "5009 -0.404461 -0.394849 -0.359648 -0.440568  0.112729 -0.370290 -0.365593  \n",
       "\n",
       "[5010 rows x 201 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.merge(y_data,rank_data_200,on = y_data.index)\n",
    "all_data = all_data.drop('key_0',axis = 1)\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = all_data.drop('gender',axis = 1)\n",
    "data_y = all_data['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_data, x_test_data, y_train_data, y_test_data = train_test_split(data_x, data_y, random_state=155)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, kernel='linear')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率为0.822825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/zourui/data/predict_user_attribute20200911/raw_data/gender/model_svm/gender_model']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(C = 1,kernel = 'linear')\n",
    "svm.fit(x_train_data, y_train_data) \n",
    "#lr.fit(x_train,y_train)\n",
    "preds = svm.predict(x_test_data)\n",
    "print('准确率为%f' %((preds==y_test_data).sum()/float(y_test_data.shape[0])))\n",
    "joblib.dump(svm, '/home/zourui/data/predict_user_attribute20200911/raw_data/gender/model_svm/gender_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dict(collections.Counter(y_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 994, 1: 259}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_data = y_train_data['gender']\n",
    "y_test_data = y_test_data['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8089  \u001b[0m | \u001b[0m 0.945   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.8089  \u001b[0m | \u001b[0m 0.7257  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8089  \u001b[0m | \u001b[0m 0.4749  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8089  \u001b[0m | \u001b[0m 0.3064  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8089  \u001b[0m | \u001b[0m 0.9188  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8089  \u001b[0m | \u001b[0m 0.02039 \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8089  \u001b[0m | \u001b[0m 0.1749  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8089  \u001b[0m | \u001b[0m 0.08641 \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8089  \u001b[0m | \u001b[0m 0.4605  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8089  \u001b[0m | \u001b[0m 0.5159  \u001b[0m |\n",
      "=====================================\n",
      "{'C': 0.9449518524012581}\n",
      "0.8088864954432478\n",
      "6250.681229829788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=0.9449518524012581, break_ties=False, cache_size=200, class_weight=None,\n",
       "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma='scale',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率为0.659619\n"
     ]
    }
   ],
   "source": [
    "def svm(C):\n",
    "    val = cross_val_score(\n",
    "        SVC(C=C\n",
    "           ),\n",
    "        x_train_data, y_train_data, scoring='accuracy',cv=10).mean()\n",
    "    return val\n",
    "t_start = time.time()\n",
    "params = {\n",
    "    'C': (0.01,1)\n",
    "    }\n",
    "svm_bo = BayesianOptimization(svm,params)\n",
    "svm_bo.maximize(init_points = 5,n_iter =5)\n",
    "params_1 = svm_bo\n",
    "params = svm_bo.max\n",
    "params = params[\"params\"]\n",
    "L = list()\n",
    "L.append(params)\n",
    "val = svm(**params)\n",
    "print(params)\n",
    "print(val)\n",
    "t_end = time.time()\n",
    "print(t_end - t_start)\n",
    "svm_classifier=SVC(C=L[0]['C'],kernel='linear')\n",
    "\n",
    "# 拟合模型\n",
    "svm_classifier.fit(x_train_data, y_train_data)\n",
    "\n",
    "# 使用模型预测\n",
    "preds = svm_classifier.predict(x_test_data)\n",
    "\n",
    "print('准确率为%f' %((preds==y_test_data).sum()/float(y_test_data.shape[0])))\n",
    "#joblib.dump(svm_classifier, '../code/model_svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=500, kernel='linear')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率为0.659619\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(C = 500,kernel = 'linear')\n",
    "svm.fit(x_train_data, y_train_data) \n",
    "#lr.fit(x_train,y_train)\n",
    "preds = svm.predict(x_test_data)\n",
    "print('准确率为%f' %((preds==y_test_data).sum()/float(y_test_data.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, kernel='linear')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率为0.659619\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(C = 1000,kernel = 'linear')\n",
    "svm.fit(x_train_data, y_train_data) \n",
    "#lr.fit(x_train,y_train)\n",
    "preds = svm.predict(x_test_data)\n",
    "print('准确率为%f' %((preds==y_test_data).sum()/float(y_test_data.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1500, kernel='linear')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率为0.659619\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(C = 1500,kernel = 'linear')\n",
    "svm.fit(x_train_data, y_train_data) \n",
    "#lr.fit(x_train,y_train)\n",
    "preds = svm.predict(x_test_data)\n",
    "print('准确率为%f' %((preds==y_test_data).sum()/float(y_test_data.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.01, kernel='linear')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率为0.659619\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(C = 0.01,kernel = 'linear')\n",
    "svm.fit(x_train_data, y_train_data) \n",
    "#lr.fit(x_train,y_train)\n",
    "preds = svm.predict(x_test_data)\n",
    "print('准确率为%f' %((preds==y_test_data).sum()/float(y_test_data.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, kernel='linear')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率为0.659619\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(C = 100,kernel = 'linear')\n",
    "svm.fit(x_train_data, y_train_data) \n",
    "#lr.fit(x_train,y_train)\n",
    "preds = svm.predict(x_test_data)\n",
    "print('准确率为%f' %((preds==y_test_data).sum()/float(y_test_data.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/zourui/data/predict_user_attribute20200911/raw_data/gender/model_svm/age_svm_model']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svm, '/home/zourui/data/predict_user_attribute20200911/raw_data/gender/model_svm/age_svm_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
