{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import collections\n",
    "import datetime\n",
    "import copy\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import happybase\n",
    "import warnings\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import csv\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =  r\"/mnt1/zhaodachuan/data/predict_user_attribute/data/raw_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt1/zhaodachuan/data/predict_user_attribute/data/raw_data/000000_0', '/mnt1/zhaodachuan/data/predict_user_attribute/data/raw_data/000002_0', '/mnt1/zhaodachuan/data/predict_user_attribute/data/raw_data/000001_0', '/mnt1/zhaodachuan/data/predict_user_attribute/data/raw_data/000003_0']\n"
     ]
    }
   ],
   "source": [
    "file_list = []\n",
    "for root,_,path_list in os.walk(data_dir):\n",
    "    for path in path_list:\n",
    "        file_list.append(os.path.join(root,path))\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 461777: expected 32 fields, saw 33\\n'\n",
      "<string>:2: DtypeWarning: Columns (1,3,4,5,6,7,15,16,28,29,30) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "<string>:2: DtypeWarning: Columns (1,2,3,4,5,6,7,15,16,28,29,30) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.1 s, sys: 2.47 s, total: 57.6 s\n",
      "Wall time: 57.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#读取用户数据\n",
    "all_file_data = []\n",
    "for file_name in file_list:\n",
    "    all_file_data.append(pd.read_csv(os.path.join(data_dir,file_name),sep='\\001',header=None,error_bad_lines=False))\n",
    "df = pd.concat(all_file_data,axis=0,ignore_index=True)\n",
    "del all_file_data\n",
    "column_list = ['用户id','用户姓名','用户性别','用户出生时间','所在公司','所处职位','行业','微信网名','微信性别','常驻省','常驻市','是否付费用户','付费等级','关注的作者','作者类型','关注的马甲','关注的公司','文章id','是否精选文章','浏览文章时间','浏览时长','文章频道','文章类型','文章标签','文章图片数量','文章字数','新定位省','新定位市','评论内容','打赏金额','设备型号','使用网络']\n",
    "df.columns = column_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "with open(\"multi_hot_column_odict.pkl\",\"rb\") as f:\n",
    "    multi_hot_column_odict = pickle.load(f)\n",
    "with open(\"y_onehot.pkl\",\"rb\") as f:\n",
    "    y_onehot = pickle.load(f)\n",
    "#with tf.device('/device:GPU:1'):\n",
    "#    model = tf.keras.models.load_model(\"model_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"model_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['1', '2'], dtype=object)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_onehot.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['关注的马甲', '关注的作者'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_hot_column_odict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['21~25', '26~29', '30~35', '36~45', '46~50', '50~', '~20'],\n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_onehot.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = df[list(multi_hot_column_odict.keys()) + [\"用户id\"]]\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>关注的马甲</th>\n",
       "      <th>关注的作者</th>\n",
       "      <th>用户id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>00001D26FE991A4BC4A01325D5E222DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>00006C3EF7F79B0F37EEFB8381505530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0000D0E1960239E8362F6B4100D9790A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0000f55e60d5ba7b36004429b235c95096f7153d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>00014E9D5CF948B3FE6376564B23F64F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15703260</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>qlu2xsthqk7tp0mncpgr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15703261</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>qlu30bysbp1mj150uc1m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15703262</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>qlu30t7n6f2b1jgzexv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15703263</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>qlu315b37v5rc273amb0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15703264</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>qlu31nan912a53u0z62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15703265 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         关注的马甲  关注的作者                                      用户id\n",
       "0           -1     -1          00001D26FE991A4BC4A01325D5E222DE\n",
       "1           -1     -1          00006C3EF7F79B0F37EEFB8381505530\n",
       "2           -1     -1          0000D0E1960239E8362F6B4100D9790A\n",
       "3           -1     -1  0000f55e60d5ba7b36004429b235c95096f7153d\n",
       "4           -1     -1          00014E9D5CF948B3FE6376564B23F64F\n",
       "...        ...    ...                                       ...\n",
       "15703260    -1     -1                      qlu2xsthqk7tp0mncpgr\n",
       "15703261    -1     -1                      qlu30bysbp1mj150uc1m\n",
       "15703262    -1     -1                       qlu30t7n6f2b1jgzexv\n",
       "15703263    -1     -1                      qlu315b37v5rc273amb0\n",
       "15703264    -1     -1                       qlu31nan912a53u0z62\n",
       "\n",
       "[15703265 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#测试数据\n",
    "warnings.filterwarnings('ignore')\n",
    "output_csv = r\"/mnt1/zhaodachuan/data/predict_user_attribute/data/age.csv\"\n",
    "with open(output_csv, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['age', 'udid' , \"probility\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i,chunk in enumerate(np.array_split(predict_df, 30000)):\n",
    "        udid_list = chunk[\"用户id\"].values.tolist()\n",
    "        predict_x = []\n",
    "        for index in chunk.index:\n",
    "            temp_x_list = []\n",
    "            for j,column in enumerate(multi_hot_column_odict):\n",
    "                split_column_list = chunk.loc[index,column].split(\",\") if isinstance(chunk.loc[index,column],str) else [str(predict_df.loc[index,column])]\n",
    "                temp_x_list.extend(multi_hot_column_odict[column].transform([split_column_list]).tolist()[0])\n",
    "            predict_x.append(temp_x_list)\n",
    "        y_predict = model.predict([predict_x])\n",
    "        #print(y_predict)\n",
    "        for y_predict_i,udid in zip(y_predict[0],udid_list):\n",
    "            writer.writerow({'age':y_onehot.inverse_transform(np.array([y_predict_i]))[0], 'udid': udid , 'probility':json.dumps(y_predict_i.tolist())})\n",
    "        if i % 300 == 0:\n",
    "            print(i)\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import happybase\n",
    "output_df = pd.read_csv(output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = happybase.ConnectionPool(size=100, host=\"47.110.125.69\", port=9090, timeout=None,\n",
    "                                protocol='binary'\n",
    "                                )\n",
    "with pool.connection() as conn:\n",
    "    table = conn.table(\"feature_center:user_profile\")\n",
    "    with table.batch(batch_size=400) as batch:\n",
    "        for i,index in enumerate(output_df.index):\n",
    "            batch.put(output_df.loc[index,\"udid\"].encode(), {\"attribute:predict_gender\".encode(): output_df.loc[index,\"gender\"].encode()})\n",
    "            #break\n",
    "            if i % 100000 == 0:\n",
    "                print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
